{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"images/mej.logo.1154x363.png\" alt = \"Drawing\" style = \"position: relative; right: 390px; width: 400px;\"/>\n",
    "\n",
    "# Calculating Cumulative EJ Impact in New Mexico\n",
    "\n",
    "\n",
    "*This notebook contains code for combining socioeconomic, health, environmental pollution and exposures data to create a single indicator of environmental injustice by census tract, which MEJ uses to create it's environmental justice maps. You can find the final maps on our website: [mappingforej.berkeley.edu](mappingforej.berkeley.edu)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "The negative effects of pollution depend on a combination of vulnerability and exposure. People living in poverty, for example, are more likely to develop asthma or die due to air pollution. The method MEJ uses, following the method developed for [CalEnviroScreen](https://oehha.ca.gov/calenviroscreen/report/calenviroscreen-30), reflects this in the two overall components of a census tract’s final “Cumulative EJ Impact”: population characteristics and pollution burden. The CalEnviroScreen methodology was developed through an intensive, multi-year effort to develop a science-backed, peer-reviewed tool to assess environmental justice in a holistic way, and has since been replicated by several other states.\n",
    "\n",
    "CalEnviroScreen Methodology:\n",
    "- Population characteristics are a combination of socioeconomic data (often referred to as the social determinants of health) and health data that together reflect a populations' vulnerability to pollutants. Pollution burden is a combination of direct exposure to a pollutant and environmental effects, which are adverse environmental conditions caused by pollutants, such as toxic waste sites or wastewater releases. Together, population characteristics and pollution burden help describe the disproportionate impact that environmental pollution has on different communities.\n",
    "\n",
    "- Every indicator is ranked as a percentile from 0 to 100 and averaged with the others of the same component to form an overall score for that component. Each component score is then percentile ranked to create a component percentile. The Sensitive Populations component score, for example, is the average of a census tract’s Asthma, Low Birthweight Infants, and Heart Disease indicator percentiles, and the Sensitive Populations component percentile is the percentile rank of the Sensitive Populations score.\n",
    "\n",
    "- The Population Characteristics score is the average of the Sensitive Populations component score and the Socioeconomic Factors component score. The Population Characteristics percentile is the percentile rank of the Population Characteristics score.\n",
    "\n",
    "- The Pollution Burden score is the average of the Pollution Exposure component score and one half of the Environmental Effects component score (Environmental Effects may have a smaller effect on health outcomes than the indicators included the Exposures component so are weighted half as much as Exposures). The Pollution Burden percentile is the percentile rank of the Pollution Burden score.\n",
    "\n",
    "- The Populaton Characteristics and Pollution Burden scores are then multiplied to find the final Cumulative EJ Impact score for a census tract, and then this final score is percentile-ranked to find a census tract's final Cumulative EJ Impact percentile.\n",
    "\n",
    "- Census tracts with no population aren't given a Population Characteristics score.\n",
    "\n",
    "- Census tracts with an indicator score of zero are assigned a percentile rank of zero. Percentile rank is then only calculated for those census tracts with a score above zero.\n",
    "\n",
    "- Census tracts that are missing data for more than two indicators don't receive a final Cumulative EJ Impact ranking.\n",
    "\n",
    "![Alt](images/Methodology_chart.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilation of all code for indicators\n",
    "\n",
    "This notebook first finds the following values for each indicator:\n",
    "- State (if applicable)\n",
    "- FIPS Census Tract ID\n",
    "- Indicator Score\n",
    "- Indicator Percentile Rank\n",
    "\n",
    "Then, these values are compiled for each indicator into one final table with all census tracts, raw indicator scores, indicator percentile ranks, component scores and percentile ranks (Environmental Exposures, Environmental Effects, Sensitive Populations, or Socioeconomic Factors), final Cumulative EJ Impact score and percentile rank, and the number of indicators that have null values when generating the final score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicators\n",
    "\n",
    "Environmental Effects Indicators:\n",
    "1. [Lead Paint](#lead)\n",
    "2. [Oil & Gas](#oil)\n",
    "3. [High-Risk Chemical Facilities](#chemical_facilities)\n",
    "4. [Hazardous Waste Facilities](#ejscreen)\n",
    "5. [Federal Cleanup Sites](#ejscreen)\n",
    "6. [Wastewater Releases](#ejscreen)\n",
    "\n",
    "Exposures Indicators:\n",
    "7. [Traffic](#ejscreen)\n",
    "8. [Ozone](#ozonepm25)\n",
    "9. [Particulate Matter (PM 2.5)](#ozonepm25)\n",
    "10. [Diesel Particulate Matter(Diesel PM)](#diesel)\n",
    "11. [Air Toxics](#air_toxics)\n",
    "\n",
    "Socioeconomic Factors Indicators:\n",
    "12. [Extreme Housing Burden](#housingburden)\n",
    "13. [No High School Degree (No HS Degree)](#no_hs)\n",
    "14. [Linguistic Isolation](#ling_iso)\n",
    "15. [Unemployment](#unemploy)\n",
    "16. [People of Color](#poc)\n",
    "17. [Poverty](#poverty)\n",
    "\n",
    "Sensitive Populations Indicators:\n",
    "18. [Asthma](#asthma)\n",
    "19. [Heart Disease](#heart_disease)\n",
    "20. [Low Birthweight Infants](#lbw)\n",
    "\n",
    "#### [Code to compile all data](#all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data\n",
    "\n",
    "You will need the following data files in your directory: \n",
    "\n",
    "\n",
    "- [data/OIL_AND_GAS_LOCATIONS_SHP/Oil_and_Gas_Locations.shp](https://cogcc.state.co.us/documents/data/downloads/gis/metadata/Oil_and_Gas_Locations_Metadata.html)\n",
    "- [data/TANK_BATTERIES_SHP/Tank_Batteries.shp](https://cogcc.state.co.us/documents/data/downloads/gis/metadata/Tank_Batteries_Metadata.html)\n",
    "- [data/PITS_SHP/Pits.shp](https://cogcc.state.co.us/documents/data/downloads/gis/metadata/Pits_Metadata.html)\n",
    "- [data/tl_2019_08_tabblock10/tl_2019_08_tabblock10.shp](https://catalog.data.gov/dataset/tiger-line-shapefile-2019-2010-state-colorado-2010-census-block-state-based)\n",
    "- data/wells_with_distance_meters/wells_with_distance_meters.shp ([available in repo](https://github.com/karmijo/mapping-for-environmental-justice/tree/master/data))\n",
    "- data/tanks_with_distance_meters/tanks_with_distance_meters.shp ([available in repo](https://github.com/karmijo/mapping-for-environmental-justice/tree/master/data))\n",
    "- data/pits_with_distance_meters/pits_with_distance_meters.shp ([available in repo](https://github.com/karmijo/mapping-for-environmental-justice/tree/master/data))\n",
    "- [data/Colorado_Census_Tract_Boundaries-shp/Colorado_Census_Tract_Boundaries.shp](https://data-cdphe.opendata.arcgis.com/datasets/a9f5b1a67bd74b2fa22279d141625335_3/data)\n",
    "- ['data/EJSCREEN_2019_USPR.csv](ftp://newftp.epa.gov/EJSCREEN/2019/)\n",
    "- data/dieselpmexposure.csv ([available in repo](https://github.com/karmijo/mapping-for-environmental-justice/tree/master/data))\n",
    "- [data/nata2014v2_national_resphi_by_tract_poll.xlsx](https://www.epa.gov/sites/production/files/2018-08/nata2014v2_national_resphi_by_tract_poll.xlsx)\n",
    "- [data/2012thru2016-140-csv/2012thru2016-140-csv/140/Table8.csv](https://www.huduser.gov/portal/datasets/cp.html)\n",
    "- [data/Asthma_Prevalence_in_Adults_-_CDPHE_Community_Level_Estimates__Census_Tracts_.csv](https://data-cdphe.opendata.arcgis.com/datasets/asthma-prevalence-in-adults-cdphe-community-level-estimates-census-tracts)\n",
    "- [data/Heart_Disease_in_Adults_-_CDPHE_Community_Level_Estimates__Census_Tracts_.csv](https://data-cdphe.opendata.arcgis.com/datasets/heart-disease-in-adults-cdphe-community-level-estimates-census-tracts)\n",
    "- [data/Low_Weight_Birth_Rate__Census_Tracts_.csv](https://data-cdphe.opendata.arcgis.com/datasets/low-weight-birth-rate-census-tracts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "import requests\n",
    "import sqlite3\n",
    "import zipfile\n",
    "from pandas.io import sql\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environmental Effects Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Lead Paint <a id='lead'></a>\n",
    "\n",
    "The lead paint indicator represents the proportion of older residences that may have lead-based paint, which can cause developmental delays, seizures, miscarriages, and other serious health problems.\n",
    "\n",
    "The lead paint indicator measures the percent of housing units built before 1980, including single homes and multiple residence units such as apartments. The age of a home is used as a marker of risk for the presence of lead paint because paint typically contains high levels of lead in the decades leading up to 1980. In the early 1970s the paint industry issued voluntary standards limiting lead content in paint, and in 1978 lead was banned from use in the manufacture of residential paint(Washington Tracking Network, 2018).\n",
    "\n",
    "Estimates of housing age comes from the U.S. Census’s most recent American Community Survey (ACS) 5-year survey detailed tables using the census API to get the estimated total number of homes and number of homes by year of construction(1970-1979, 1960-1969, 1950-1959, 1940-1949, and before 1940). Different housing “vintages” have different odds of containing lead paint, so the number of homes built during the given periods are weighted with the following weights: 1940 = 0.68; 1940-1959 = 0.43; 1960-1979 = 0.08. These weights are then summed for each census tract and census tracts are ranked according to their score. Census tracts with no estimated homes are given a null score and rank. This follows Washington’s Environmental Health Disparities Map methodology, which can be found [here](https://fortress.wa.gov/doh/wtn/WTNPortal#!q0=722). \n",
    "\n",
    "Note that this code creates a lead score and rank by state, for every state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACS 2018 5-year detailed tables [variables](https://api.census.gov/data/2018/acs/acs5/variables.html):\n",
    "\n",
    "|    Name   |                          Label                      |       Concept      |\n",
    "|-----------|-----------------------------------------------------|--------------------|\n",
    "|B25034_001E|                     Estimate Total                  |Year Structure Built|\n",
    "|B25034_007E|           Estimate Total Built 1970 to 1979         |Year Structure Built|\n",
    "|B25034_008E|           Estimate Total Built 1960 to 1969         |Year Structure Built|\n",
    "|B25034_009E|           Estimate Total Built 1950 to 1959         |Year Structure Built|\n",
    "|B25034_010E|           Estimate Total Built 1940 to 1949         |Year Structure Built|\n",
    "|B25034_011E|         Estimate Total Built 1939 or earlier        |Year Structure Built|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# create an empty dataframe that will contain age of housing for all states\n",
    "lead = pd.DataFrame(columns = ['NAME',\n",
    "                               'state',\n",
    "                               'county',\n",
    "                               'tract',\n",
    "                               'B25034_001E',\n",
    "                               'B25034_007E',\n",
    "                               'B25034_008E',\n",
    "                               'B25034_009E',\n",
    "                               'B25034_010E',\n",
    "                               'B25034_011E'])\n",
    "\n",
    "# Create the census api request to retrieve data\n",
    "date = \"2018\"\n",
    "dataset = '/acs/acs5'\n",
    "base_url = \"https://api.census.gov/data\"\n",
    "variables = \"NAME,B25034_001E,B25034_007E,B25034_008E,B25034_009E,B25034_010E,B25034_011E\"\n",
    "\n",
    "# Get all FIPS state codes in strings (01 - 56) \n",
    "# FIPS state codes can be found here: https://en.wikipedia.org/wiki/Federal_Information_Processing_Standard_state_code\n",
    "state_codes = list(np.arange(1, 56))\n",
    "states = list(map(str, np.arange(1, 56)))\n",
    "states = list(map(lambda x: str.zfill(x, 2), states))\n",
    "\n",
    "# remove reserved codes that aren't included in the census (e.g. American Samoa, Guam, etc.):\n",
    "states.remove('03')\n",
    "states.remove('07')\n",
    "states.remove('14')\n",
    "states.remove('43')\n",
    "states.remove('52')\n",
    "\n",
    "# Request data for each state and add to dataframe for all states \n",
    "for state in states:\n",
    "    query = base_url + \"/\" + date + dataset + \"?get=\" + variables + '&for=' + 'tract:*&in=state:' + state\n",
    "\n",
    "    state_df = pd.read_json(query, dtype = True)\n",
    "    state_df.columns = state_df.iloc[0]\n",
    "    state_df = state_df.drop(state_df.index[0])\n",
    "    \n",
    "    # Concat all data into one table\n",
    "    lead = pd.concat([lead, state_df[['NAME',\n",
    "                                      'state',\n",
    "                                      'county',\n",
    "                                      'tract',\n",
    "                                      'B25034_001E',\n",
    "                                      'B25034_007E',\n",
    "                                      'B25034_008E',\n",
    "                                      'B25034_009E',\n",
    "                                      'B25034_010E',\n",
    "                                      'B25034_011E']]], sort = 'True', ignore_index = True)\n",
    "\n",
    "# Rename columns\n",
    "lead = lead.rename(columns = {\n",
    "    'B25034_001E':'total_houses',\n",
    "    \"B25034_007E\": \"1970-1979\",\n",
    "    \"B25034_008E\": \"1960-1969\",\n",
    "    \"B25034_009E\": \"1950-1959\",\n",
    "    \"B25034_010E\": \"1940-1949\", \n",
    "    \"B25034_011E\": \"pre_1940\"})\n",
    "\n",
    "# Make sure all data are ints, not strings \n",
    "lead['pre_1940'] = lead['pre_1940'].astype(int)\n",
    "lead['1940-1949'] = lead['1940-1949'].astype(int)\n",
    "lead['1950-1959'] = lead['1950-1959'].astype(int)\n",
    "lead['1960-1969'] = lead['1960-1969'].astype(int)\n",
    "lead['1970-1979'] = lead['1970-1979'].astype(int)\n",
    "lead['total_houses'] = lead['total_houses'].astype(int)\n",
    "\n",
    "# Condense into ranges pre-1940, 1940-1959, 1960-1979\n",
    "lead['1940-1959'] = lead['1940-1949'] + lead['1950-1959']\n",
    "lead['1960-1979'] = lead['1960-1969'] + lead['1970-1979']\n",
    "\n",
    "# Construct FIPS Code to tract level\n",
    "lead['FIPS_tract_id'] = lead['state'] + lead['county'] + lead['tract']\n",
    "\n",
    "# Weight each range correspondingly and create overall lead score\n",
    "# Set score to null value if currently no houses\n",
    "lead['lead_score'] = np.nan\n",
    "for row in range(len(lead)):\n",
    "    if lead['total_houses'].iloc[row] != 0:\n",
    "        lead['lead_score'].iloc[row] = ((0.68 * lead['pre_1940'].iloc[row]) + # column 9 = pre_1940\n",
    "                                         (0.43 * lead['1940-1959'].iloc[row]) + # column 10 = 1940-1959\n",
    "                                         (0.08 * lead['1960-1979'].iloc[row])) / lead['total_houses'].iloc[row] # column 11 = 1960-1979\n",
    "\n",
    "# Calculate percentile rank for census tracts with a score above 0, set percentile to 0 if score is 0\n",
    "lead['lead_rank'] = lead[lead['lead_score'] != 0][['lead_score','state']].groupby('state').rank(\n",
    "    na_option = 'keep', \n",
    "    pct = True)*100\n",
    "lead.loc[lead['lead_score'] == 0, 'lead_rank'] = 0\n",
    "\n",
    "# Create final table with only NAME, FIPS tract id, score, percentile ranking, name, and state\n",
    "lead = lead[['NAME','state', 'FIPS_tract_id', 'lead_score', 'lead_rank']]\n",
    "NM_lead = lead[lead['state'] == '35']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Oil & Gas <a id='oil'></a>\n",
    "\n",
    "The Oil & Gas indicator represents oil and gas facilities that include wells, wastewater pits, and tanks of oil or other dangerous chemicals located near populated areas. Oil and gas operations have been linked to many health problems in nearby communities including headaches, nausea, cancer, asthma, and birth defects.\n",
    "\n",
    "The Oil & Gas indicator measures the count in each census tract of all oil and gas facilities, including wells, tanks, pits, within 1 kilometer of a populated census block, where each site is weighted by it’s distance to the nearest populated census block. Oil wells, tanks, and pits location data from 1999-2020 is sourced from the [Colorado Oil and Gas Conservation Commission](https://cogcc.state.co.us/data2.html#/downloads). The distancing weighting method is modelled after CalEnviroScreen’s method for distance weighting using the same following weights: 1 if the site is less than 250 meters from a populated census block, 0.5 if the site is 250-500 meters from a populated census block, 0.25 if the site is 500-750 meters from a populated census block, and 0.1 if the site is 750-1000 meters from a populated census block. All facilities further than 1,000 meters from any populated census blocks were excluded (CalEnviroScreen, 2017).\n",
    "\n",
    "- Data for the number of wells can be found [here](https://cogcc.state.co.us/documents/data/downloads/gis/metadata/Oil_and_Gas_Locations_Metadata.html) under \"Oil & Gas Locations (3.7 Mb)\".\n",
    "- Data for the number of pits can be found [here](https://cogcc.state.co.us/documents/data/downloads/gis/metadata/Pits_Metadata.html) under \"Pits (1 Mb)\".\n",
    "- Data for the number of tank batteries can be found [here](https://cogcc.state.co.us/documents/data/downloads/gis/metadata/Tank_Batteries_Metadata.html) under \"Tank Batteries (87 Kb)\".\n",
    "\n",
    "Note: The [state](https://cogcc.state.co.us/documents/about/COGIS_Help/Status_Codes.pdf) of the well (ex. not active anymore, just being drilled, etc.), where the older the well is the less harmful it is currently, is not currently incorporated in this analysis.\n",
    "\n",
    "Finally, this indicator is only calculated for the state of Colorado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "DriverError",
     "evalue": "data/OIL_AND_GAS_LOCATIONS_SHP/Oil_and_Gas_Locations.shp: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32mfiona/_shim.pyx\u001b[0m in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfiona/_err.pyx\u001b[0m in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: data/OIL_AND_GAS_LOCATIONS_SHP/Oil_and_Gas_Locations.shp: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDriverError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-cdae4628c45d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Oil and gas facilities data: https://cogcc.state.co.us/documents/data/downloads/gis/metadata/Oil_and_Gas_Locations_Metadata.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moil_gas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/OIL_AND_GAS_LOCATIONS_SHP/Oil_and_Gas_Locations.shp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Tank battery data: https://cogcc.state.co.us/documents/data/downloads/gis/metadata/Tank_Batteries_Metadata.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Tank Battery is a device used to store crude oil which is produced from a well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/geopandas/io/file.py\u001b[0m in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfiona_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;31m# In a future Fiona release the crs attribute of features will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/fiona/env.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/fiona/__init__.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             c = Collection(path, mode, driver=driver, encoding=encoding,\n\u001b[0m\u001b[1;32m    257\u001b[0m                            layer=layer, enabled_drivers=enabled_drivers, **kwargs)\n\u001b[1;32m    258\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/fiona/collection.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWritingSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.Session.start\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfiona/_shim.pyx\u001b[0m in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDriverError\u001b[0m: data/OIL_AND_GAS_LOCATIONS_SHP/Oil_and_Gas_Locations.shp: No such file or directory"
     ]
    }
   ],
   "source": [
    "# Oil and gas facilities data: https://cogcc.state.co.us/documents/data/downloads/gis/metadata/Oil_and_Gas_Locations_Metadata.html\n",
    "oil_gas = gpd.read_file(\"data/OIL_AND_GAS_LOCATIONS_SHP/Oil_and_Gas_Locations.shp\")\n",
    "\n",
    "# Tank battery data: https://cogcc.state.co.us/documents/data/downloads/gis/metadata/Tank_Batteries_Metadata.html\n",
    "# Tank Battery is a device used to store crude oil which is produced from a well.\n",
    "tank_batteries = gpd.read_file(\"data/TANK_BATTERIES_SHP/Tank_Batteries.shp\")\n",
    "\n",
    "# Oil pits data: https://cogcc.state.co.us/documents/data/downloads/gis/metadata/Pits_Metadata.html\n",
    "pits = gpd.read_file(\"data/PITS_SHP/Pits.shp\")\n",
    "\n",
    "# Create empty list for non-populated blocks, which will be filtered by GEOID to get unique codes\n",
    "nonpop_blocks = []\n",
    "\n",
    "# Get all county codes in Colorado: https://simple.wikipedia.org/wiki/List_of_counties_in_Colorado\n",
    "# 001 - 125 by odd nums\n",
    "counties = list(map(str, np.arange(1, 127, 2)))\n",
    "counties = list(map(lambda x: str.zfill(x, 3), counties))\n",
    "\n",
    "# Get population data using the Census Decennial Summary File 1 (SF1) from 2010 because it goes down to block level\n",
    "# ACS5 has more recent population data from 2018, but only goes down to block group level\n",
    "# Find Decennial SF1 in 2010 at https://api.census.gov/data.html \n",
    "# Colorado is state code 08\n",
    "# Must use for loop over all counties because api doesn't allow iteration over all blocks at once \n",
    "for county_code in counties: \n",
    "    url = \"https://api.census.gov/data/2010/dec/sf1?get=NAME,group(P1)&for=block:*&in=state:08%county:\" + county_code\n",
    "    r = requests.get(url)\n",
    "\n",
    "    r.raise_for_status()\n",
    "    \n",
    "    data = r.json()\n",
    "\n",
    "    blocks = pd.DataFrame(data)\n",
    "    blocks.columns = blocks.iloc[0]\n",
    "    blocks = blocks.iloc[1:]\n",
    "\n",
    "    # Convert total population data to integers\n",
    "    # P001001\tTotal\tTOTAL POPULATION\n",
    "    blocks['P001001'] = blocks['P001001'].apply(int)\n",
    "    \n",
    "    # Add block geoids where total population is 0 to the nonpopulated list\n",
    "    nonpop_blocks.extend(blocks[blocks['P001001'] == 0]['GEO_ID'].values.tolist())\n",
    "\n",
    "# Get rid of first '1000000US' of strings in geoid\n",
    "nonpop_blocks = pd.Series(nonpop_blocks).apply(lambda x: x[9:])\n",
    "\n",
    "# Read in Colorado census block shapes data\n",
    "# Data found at https://catalog.data.gov/dataset/tiger-line-shapefile-2019-2010-state-colorado-2010-census-block-state-based\n",
    "block_shapes = gpd.read_file(\"data/tl_2019_08_tabblock10/tl_2019_08_tabblock10.shp\")\n",
    "\n",
    "# Filter out blocks with no population\n",
    "block_shapes_pop = block_shapes[~block_shapes['GEOID10'].isin(nonpop_blocks)]\n",
    "\n",
    "# Read in data containing distances to closest populated block for each well, tank, and pit, calculated using QGIS\n",
    "wells_dists = gpd.read_file(\"data/wells_with_distance_meters/wells_with_distance_meters.shp\")\n",
    "tanks_dists = gpd.read_file(\"data/tanks_with_distance_meters/tanks_with_distance_meters.shp\")\n",
    "pits_dists = gpd.read_file(\"data/pits_with_distance_meters/pits_with_distance_meters.shp\")\n",
    "\n",
    "# Filter out sites further than 1 kilometer, or 1000 meters, from a populated block\n",
    "wells_within_onekm = wells_dists[wells_dists['distance'] <= 1000]\n",
    "tanks_within_onekm = tanks_dists[tanks_dists['distance'] <= 1000]\n",
    "pits_within_onekm = pits_dists[pits_dists['distance'] <= 1000]\n",
    "\n",
    "# Create 1 km buffers around each census tract\n",
    "# To create a weighted aggregate of the oil sites in each buffered census tract\n",
    "# Using CO census tract shapefile from CDPHE here: https://data- cdphe.opendata.arcgis.com/datasets/a9f5b1a67bd74b2fa22279d141625335_3/data\n",
    "tracts = gpd.read_file(\"data/Colorado_Census_Tract_Boundaries-shp/Colorado_Census_Tract_Boundaries.shp\")\n",
    "tracts = tracts.drop(columns = [\"OBJECTID\"])\n",
    "\n",
    "# Convert buffer distance from kilometers to degrees\n",
    "lat_radians = 39.7392 * np.pi/180\n",
    "buff_dist = 1/(111.32*np.cos(lat_radians))\n",
    "\n",
    "# Add buffers to census tracts\n",
    "tracts_buffered = tracts.apply(lambda x: x.iloc[-1].buffer(buff_dist), axis = 1) # axis = 1 to apply to each row\n",
    "tracts_buffered_df = tracts\n",
    "tracts_buffered_df['geometry'] = tracts_buffered\n",
    "\n",
    "# List all instances of wells within 1km of a populated block with the corresponding buffered census tract(s) they intersect with\n",
    "# Before doing spatial join of the buffered tracts and wells within one km\n",
    "# Convert crs to be same\n",
    "tracts_buffered_df = tracts_buffered_df.to_crs(wells_within_onekm.crs)\n",
    "\n",
    "# Spacial join points to polygons of the buffered tracts and wells within one km\n",
    "wells_joined = gpd.sjoin(tracts_buffered_df, wells_within_onekm, op = 'intersects')\n",
    "\n",
    "# Weight each site based on CalEnviroscreen weights/distances method\n",
    "# 1 : <=250m\n",
    "# 0.5: <=500m\n",
    "# 0.25: <=750m\n",
    "# 0.1: <=1000m\n",
    "# Make a column to turn into weights\n",
    "wells_joined['weights'] = wells_joined['distance']\n",
    "\n",
    "# Assign weights\n",
    "wells_joined['weights'] = np.where(wells_joined['distance'] <= 250, 1, \n",
    "                                     np.where(wells_joined['distance'] <= 500, 0.5,\n",
    "                                     np.where(wells_joined['distance'] <= 750, 0.25,\n",
    "                                     np.where(wells_joined['distance'] <= 1000, 0.1,0))))\n",
    "\n",
    "# Sum weights for each census tract\n",
    "wells_agg = wells_joined.groupby('FIPS').sum()[['weights']].reset_index().rename(columns = {\n",
    "    'FIPS':'FIPS_tract_id', \n",
    "    'weights':'wells_agg'\n",
    "})\n",
    "\n",
    "# Repeat for tanks\n",
    "# List all instances of tanks within 1km of a populated block with the corresponding buffered census tract(s) they intersect with\n",
    "# Using a spatial join points to polygons\n",
    "tanks_joined = gpd.sjoin(tracts_buffered_df, tanks_within_onekm, op = 'intersects') \n",
    "\n",
    "\n",
    "# Make a column to turn into weights\n",
    "tanks_joined['weights'] = tanks_joined['distance']\n",
    "\n",
    "#assign weights\n",
    "tanks_joined['weights'] = np.where(tanks_joined['distance'] <= 250, 1, \n",
    "                                     np.where(tanks_joined['distance'] <= 500, 0.5,\n",
    "                                     np.where(tanks_joined['distance'] <= 750, 0.25,\n",
    "                                     np.where(tanks_joined['distance'] <= 1000, 0.1,0))))\n",
    "\n",
    "# Sum weights for each census tract\n",
    "tanks_agg = tanks_joined.groupby('FIPS').sum()[['weights']].reset_index().rename(columns = {\n",
    "    'FIPS':'FIPS_tract_id', \n",
    "    'weights':'tanks_agg'\n",
    "})\n",
    "\n",
    "# Repeat for pits\n",
    "# List all instances of pits within 1km of a populated block with the corresponding buffered census tract(s) they intersect with\n",
    "# Using a spatial join points to polygons\n",
    "pits_joined = gpd.sjoin(tracts_buffered_df, pits_within_onekm, op = 'intersects')\n",
    "\n",
    "\n",
    "# Make a column to turn into weights\n",
    "pits_joined['weights'] = pits_joined['distance']\n",
    "\n",
    "# Assign weights\n",
    "pits_joined['weights'] = np.where(pits_joined['distance'] <= 250, 1, \n",
    "                                     np.where(pits_joined['distance'] <= 500, 0.5,\n",
    "                                     np.where(pits_joined['distance'] <= 750, 0.25,\n",
    "                                     np.where(pits_joined['distance'] <= 1000, 0.1,0))))\n",
    "\n",
    "# Sum weights for each census tract\n",
    "pits_agg = pits_joined.groupby('FIPS').sum()[['weights']].reset_index().rename(columns = {\n",
    "    'FIPS':'FIPS_tract_id', \n",
    "    'weights':'pits_agg'\n",
    "})\n",
    "\n",
    "# Merge all wells, pits, and tanks weighted sums for each census tract\n",
    "merged_oil = tanks_agg.merge(wells_agg, \n",
    "                             on = \"FIPS_tract_id\", \n",
    "                             how = 'outer').merge(pits_agg, \n",
    "                                                  on = 'FIPS_tract_id', \n",
    "                                                  how = 'outer')\n",
    "oil_gas = merged_oil[['tanks_agg', 'wells_agg', 'pits_agg']].sum(axis=1)\n",
    "oil_gas = oil_gas.to_frame().rename(columns = { 0 : 'oil_score'})\n",
    "oil_gas[\"FIPS_tract_id\"] = merged_oil[\"FIPS_tract_id\"]\n",
    "\n",
    "# Merge in census tracts with an oil score of 0\n",
    "block_shapes['FIPS_tract_id'] = block_shapes['STATEFP10'] + block_shapes['COUNTYFP10'] + block_shapes['TRACTCE10']\n",
    "all_tracts = block_shapes['FIPS_tract_id'].to_frame().drop_duplicates()\n",
    "oil_gas = oil_gas.merge(all_tracts, on = \"FIPS_tract_id\", how = 'outer', validate = 'one_to_one')\n",
    "oil_gas.loc[oil_gas['oil_score'].isnull(), ['oil_score']] = 0\n",
    "            \n",
    "# Calculate percentile rank for census tracts with a score above 0, set percentile rank to 0 if score is 0\n",
    "oil_gas['oil_rank'] = oil_gas[oil_gas['oil_score'] != 0]['oil_score'].rank( \n",
    "    na_option = 'keep', \n",
    "    pct = True)*100      \n",
    "oil_gas.loc[oil_gas['oil_score'] == 0, 'oil_rank'] = 0\n",
    "            \n",
    "# Add in Colorado state identifier\n",
    "oil_gas['state'] = '08'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - 7 . High-Risk Chemical Facilities, Hazardous Waste Facilities, Federal Cleanup Sites, Wastewater Releases, Traffic <a id='ejscreen'></a>\n",
    "\n",
    "The data for these five indicators comes from the same datasource: [EJSCREEN](ftp://newftp.epa.gov/EJSCREEN/2019/). Therefore, the following code, processes all five indicators together. A brief summary from EJSCREEN on each indicators' methodology is provided below.\n",
    "\n",
    "Note that this code creates scores and ranks for the following indicators by state, for every state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. High-Risk Chemical Facilities\n",
    "\n",
    "The High-Risk Chemical Facilities indicator represents facilities that maintain highly toxic, flammable, or explosive substances that may release acutely toxic substances which can cause serious health effects or death.\n",
    "\n",
    "The High-Risk Chemical Facilities indicator measures the proximity to Risk Management Plan sites, calculated as the count of Risk Management Plan sites within 5 kilometers of a census block centroid as of 2019, divided by the distance, presented as population-weighted averages of blocks in each block group (EJSCREEN, 2019). Risk Management Plan sites are facilities required by the Clean Air Act to file risk management plans because they maintain a quantity of a regulated substance that is highly toxic, flammable, or explosive above the given threshold (EJSCREEN, 2019). Adjustments are made if there are no Risk Management Plan sites within 5 kilometers of a census block, to ensure that the minimum distance used is reasonable when very small, and to convert census block measures to the census tract level. This data is processed by and obtained from the EPA’s [EJSCREEN](https://www.epa.gov/ejscreen). EJSCREEN names this indicator \"Proximity to Risk Management Plan (RMP) Sites\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Hazardous Waste Facilities\n",
    "\n",
    "The Hazardous Waste Facilities indicator represents facilities that treat, store, or dispose of volatile substances that are dangerous to humans and may reach people through the air or water.\n",
    "\n",
    "The Hazardous Waste Facilities indicator measures the proximity to hazardous waste treatment, storage, and disposal facilities , calculated as the count of facilities within 5 kilometers of a census block centroid as of 2019, divided by the distance, presented as population-weighted averages of blocks in each block group (EJSCREEN, 2019). Adjustments are made if there are no facilities within 5 kilometers of a census block, to ensure that the minimum distance used is reasonable when very small, and to convert census block measures to the census tract level. This data is processed by and obtained from the EPA’s [EJSCREEN](https://www.epa.gov/ejscreen). EJSCREEN names this indicator \"Proximity to Hazardous Waste Facilities\" or \"Proximity to Treatment, Storage or Disposal Facilities (TSDFs)\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Federal Cleanup Sites\n",
    "\n",
    "The Federal Cleanup Sites indicator represents federal cleanup sites, or “Superfund sites,” where extremely hazardous chemicals have been dumped or otherwise poorly managed and may reach humans through the air or water, threatening human health.\n",
    "\n",
    "The Federal Cleanup Sites indicator measures the proximity to National Priorities List Superfund sites, calculated as the count of National Priorities List Superfund sites within 5 kilometers of a census block centroid as of 2019, divided by the distance, presented as population-weighted averages of blocks in each block group (EJSCREEN, 2019). Adjustments are made if there are no National Priorities List Superfund sites within 5 kilometers of a census block, to ensure that the minimum distance used is reasonable when very small, and to convert census block measures to the census tract level. This data is processed by and obtained from the EPA’s [EJSCREEN](https://www.epa.gov/ejscreen). EJSCREEN names this indicator \"Proximity to National Priority List (NPL) Sites\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Wastewater Releases\n",
    "\n",
    "The Wastewater Releases indicator represents wastewater discharges into streams and other water sources may come from industrial, commercial, or agricultural sources and contain pollutants that can cause water-borne illnesses and diseases.\n",
    "\n",
    "The Wastewater Releases indicator measures the toxicity-weighted concentration in streams within 500 meters of a block centroid, divided by distance in meters, presented as the population-weighted average of blocks in each block group in 2017 (EPA EJSCREEN, 2019). Adjustments are made to ensure that the minimum distance used is reasonable when very small and to convert census block measures to the census tract level. This data is processed and obtained from the EPA’s [EJSCREEN](https://www.epa.gov/ejscreen). EJSCREEN names this indicator \"Wastewater Discharge Indicator (Stream Proximity and Toxicicy-Weighted Concentration)\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exposures Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Traffic\n",
    "\n",
    "The Traffic indicator represents a significant source of air pollution, particularly in urban areas, and has a wide range of negative effects including noise, vibration, injuries, illnesses and diseases due to air pollution. \n",
    "\n",
    "The Traffic indicator measures traffic proximity and volume, as the average annual traffic in 2017, or the count of vehicles per day, on major roads within 500 meters of a census block centroid, divided by distance in meters, presented as the population-weighted average of census blocks in each block group (EPA EJSCREEN, 2019). Adjustments are made to ensure that the minimum distance used is reasonable when very small and to convert census block measures to the census tract level. This data is processed and obtained from the EPA’s [EJSCREEN](https://www.epa.gov/ejscreen). EJSCREEN names this indicator \"Traffic Proximity and Volume\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the EJScreen data accessing only the columns we need\n",
    "ejscreen = pd.read_csv('data/EJSCREEN_2019_USPR.csv', usecols = [1,2,30,31,32,33,34,35,36], \n",
    "                       dtype = {'ID': str}, delimiter = ',')\n",
    "\n",
    "# Create a new column to uniquely identify tracts (gets rid of 12th digit representing block group)\n",
    "ejscreen['FIPS_tract_id'] = ejscreen['ID'].str[:-1]\n",
    "\n",
    "# Create a new column to uniquely identify states (first 2 digits)\n",
    "ejscreen['State_ID'] = ejscreen['ID'].str[0:2]\n",
    "\n",
    "# Replace 'None' values with nan values\n",
    "ejscreen[['PTRAF', \n",
    "          'PTSDF',\n",
    "          'PRMP',\n",
    "          'PWDIS',\n",
    "          'PNPL',\n",
    "          'ACSTOTPOP']] = ejscreen[['PTRAF',\n",
    "                                    'PTSDF',\n",
    "                                    'PRMP',\n",
    "                                    'PWDIS',\n",
    "                                    'PNPL',\n",
    "                                    'ACSTOTPOP']].replace('None', np.nan)\n",
    "\n",
    "# Change data types from objects\n",
    "ejscreen[['PTRAF', \n",
    "          'PTSDF',\n",
    "          'PRMP',\n",
    "          'PWDIS',\n",
    "          'PNPL',\n",
    "          'ACSTOTPOP']] = ejscreen[['PTRAF',\n",
    "                                    'PTSDF',\n",
    "                                    'PRMP',\n",
    "                                    'PWDIS',\n",
    "                                    'PNPL',\n",
    "                                    'ACSTOTPOP']].astype(float)\n",
    "\n",
    "# Find total population of each tract by summing corresponding block groups \n",
    "# (which now all have the same FIPS tract id)\n",
    "tracts_pop = ejscreen[['FIPS_tract_id', 'ACSTOTPOP']].groupby(\n",
    "    'FIPS_tract_id', \n",
    "    as_index = False).sum().rename(columns = {'ACSTOTPOP':'Tract_Pop'})\n",
    "\n",
    "# Create new dataframe that for each block group row, specifies total tract population \n",
    "# for the tract in which the block group is located\n",
    "# selecting only the 5 indicators and shape information when merging.\n",
    "ejscreen_pop = pd.merge(ejscreen[['ID','State_ID','FIPS_tract_id','PTRAF','PTSDF','PRMP','PWDIS','PNPL','ACSTOTPOP']], \n",
    "                        tracts_pop[['FIPS_tract_id','Tract_Pop']], \n",
    "                        on = 'FIPS_tract_id').rename(columns = {'ACSTOTPOP' : 'Block_Pop'})\n",
    "\n",
    "# Create a new column that gives proportion of population that each block group contributes\n",
    "ejscreen_pop['Tract_Proportion'] = ejscreen_pop['Block_Pop'] / ejscreen_pop['Tract_Pop']\n",
    "\n",
    "# Create new column with how much each block group contributes to the indicator\n",
    "ejscreen_pop['PTRAF_prop'] = ejscreen_pop['PTRAF'] * ejscreen_pop['Tract_Proportion']\n",
    "ejscreen_pop['PTSDF_prop'] = ejscreen_pop['PTSDF'] * ejscreen_pop['Tract_Proportion']\n",
    "ejscreen_pop['PRMP_prop'] = ejscreen_pop['PRMP'] * ejscreen_pop['Tract_Proportion']\n",
    "ejscreen_pop['PWDIS_prop'] = ejscreen_pop['PWDIS'] * ejscreen_pop['Tract_Proportion']\n",
    "ejscreen_pop['PNPL_prop'] = ejscreen_pop['PNPL'] * ejscreen_pop['Tract_Proportion']\n",
    "ejscreen_pop.drop(columns = {'PTRAF','PTSDF','PRMP','PWDIS','PNPL'}, inplace = True)\n",
    "\n",
    "# Create table with tract-average values for every tract\n",
    "# Sums the proportions of all the block groups of a tract to create a total weighted average for each tract\n",
    "ejscreen_tracts = ejscreen_pop[[\n",
    "    'FIPS_tract_id', \n",
    "    'PTRAF_prop', \n",
    "    'PTSDF_prop', \n",
    "    'PRMP_prop', \n",
    "    'PWDIS_prop', \n",
    "    'PNPL_prop']].groupby('FIPS_tract_id', as_index = False).sum().rename(columns = {\n",
    "    'PTRAF_prop':'PTRAF_score', \n",
    "    'PTSDF_prop':'PTSDF_score', \n",
    "    'PRMP_prop':'PRMP_score', \n",
    "    'PWDIS_prop':'PWDIS_score', \n",
    "    'PNPL_prop':'PNPL_score'})\n",
    "\n",
    "# Add in the State ID column\n",
    "ejscreen_tracts = pd.merge(ejscreen[['State_ID','FIPS_tract_id']], \n",
    "                           ejscreen_tracts[['FIPS_tract_id',\n",
    "                                            'PTRAF_score',\n",
    "                                            'PTSDF_score',\n",
    "                                            'PRMP_score',\n",
    "                                            'PWDIS_score',\n",
    "                                            'PNPL_score']], \n",
    "                           on = 'FIPS_tract_id')\n",
    "\n",
    "# Rename columns\n",
    "ejscreen_tracts = ejscreen_tracts.rename(columns = {\n",
    "    'State_ID' : 'state',\n",
    "    'PTRAF_score' : 'traf_score',\n",
    "    'PTSDF_score' : 'hazw_score',\n",
    "    'PRMP_score' : 'chem_score',\n",
    "    'PWDIS_score' : 'wat_score',\n",
    "    'PNPL_score' : 'cln_score'\n",
    "})\n",
    "\n",
    "# Calculate percentile rank for census tracts with a score above 0, set percentile to 0 if score is 0\n",
    "# For each indicator in each state\n",
    "ejscreen_tracts['traf_rank'] = ejscreen_tracts[\n",
    "    ejscreen_tracts['traf_score'] != 0][['traf_score','state']].groupby('state').rank(\n",
    "    na_option = 'keep', \n",
    "    pct = True) * 100\n",
    "ejscreen_tracts.loc[ejscreen_tracts['traf_score'] == 0, 'traf_rank'] = 0\n",
    "ejscreen_tracts['hazw_rank'] = ejscreen_tracts[\n",
    "    ejscreen_tracts['hazw_score'] != 0][['hazw_score','state']].groupby('state').rank(\n",
    "    na_option = 'keep', \n",
    "    pct = True) * 100\n",
    "ejscreen_tracts.loc[ejscreen_tracts['hazw_score'] == 0, 'hazw_rank'] = 0\n",
    "ejscreen_tracts['chem_rank'] = ejscreen_tracts[\n",
    "    ejscreen_tracts['chem_score'] != 0][['chem_score','state']].groupby('state').rank(\n",
    "    na_option = 'keep', \n",
    "    pct = True) * 100\n",
    "ejscreen_tracts.loc[ejscreen_tracts['chem_score'] == 0, 'chem_rank'] = 0\n",
    "ejscreen_tracts['wat_rank'] = ejscreen_tracts[\n",
    "    ejscreen_tracts['wat_score'] != 0][['wat_score','state']].groupby('state').rank( \n",
    "    na_option = 'keep', \n",
    "    pct = True) * 100\n",
    "ejscreen_tracts.loc[ejscreen_tracts['wat_score'] == 0, 'wat_rank'] = 0\n",
    "ejscreen_tracts['cln_rank'] = ejscreen_tracts[\n",
    "    ejscreen_tracts['cln_score'] != 0][['cln_score','state']].groupby('state').rank(\n",
    "    na_option = 'keep', \n",
    "    pct = True) * 100\n",
    "ejscreen_tracts.loc[ejscreen_tracts['cln_score'] == 0, 'cln_rank'] = 0\n",
    "\n",
    "# Create seperate tables for each indicators\n",
    "chemicals = ejscreen_tracts[['state', 'FIPS_tract_id', 'chem_score', 'chem_rank']]\n",
    "haz_waste = ejscreen_tracts[['state', 'FIPS_tract_id', 'hazw_score', 'hazw_rank']]\n",
    "cleanups = ejscreen_tracts[['state', 'FIPS_tract_id', 'cln_score', 'cln_rank']]\n",
    "water = ejscreen_tracts[['state', 'FIPS_tract_id', 'wat_score', 'wat_rank']]\n",
    "traffic = ejscreen_tracts[['state', 'FIPS_tract_id', 'traf_score', 'traf_rank']]\n",
    "\n",
    "# Drop duplicate tracts\n",
    "chemicals.drop_duplicates(subset = \"FIPS_tract_id\", keep = 'first', inplace = True, ignore_index = True)\n",
    "haz_waste.drop_duplicates(subset = \"FIPS_tract_id\", keep = 'first', inplace = True, ignore_index = True)\n",
    "cleanups.drop_duplicates(subset = \"FIPS_tract_id\", keep = 'first', inplace = True, ignore_index = True)\n",
    "water.drop_duplicates(subset = \"FIPS_tract_id\", keep = 'first', inplace = True, ignore_index = True)\n",
    "traffic.drop_duplicates(subset = \"FIPS_tract_id\", keep = 'first', inplace = True, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isolate the data for New Mexico\n",
    "NM_chemicals = chemicals[chemicals['state'] == '35']\n",
    "NM_haz_waste = haz_waste[haz_waste['state'] == '35']\n",
    "NM_cleanups = cleanups[cleanups['state'] == '35']\n",
    "NM_water = water[water['state'] == '35']\n",
    "NM_traffic = traffic[traffic['state'] == '35']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 - 9. Ozone and Particulate Matter 2.5 (PM 2.5) <a id='ozonepm25'></a> \n",
    "\n",
    "The data for these two indicators is similarly processed and comes from the same datasource: [EJSCREEN](ftp://newftp.epa.gov/EJSCREEN/2019/). Therefore, the following code, processes these two indicators together. A brief summary from EJSCREEN and MEJ on each indicators' methodology is provided below.\n",
    "\n",
    "Note that this code creates scores and ranks for the following indicators by state, for every state.\n",
    "\n",
    "Notes:\n",
    "* The census block results for Ozone and PM 2.5 presented by EJSCREEN are actually census tract values distributed homogeneously across all census blocks within a census tract; therefore, one block value within a tract is used to represent the census tract ozone value.\n",
    "* Ozone and PM 2.5 estimates are not available for Alaska or Hawaii for use in the 2019 version of EJSCREEN, due to a lack of CMAQ modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Ozone\n",
    "\n",
    "The Ozone indicator represents ozone, a chemical that combines with other air pollutants to form smog and is a widespread and significant health threat.\n",
    "\n",
    "The Ozone indicator measures ground-level ozone concentrations in the air in parts per billion (ppb). This data is estimated by the EPA using a combination of monitoring data and CMAQ air quality modeling from 2016 and describes the daily maximum 8-hour ozone concentration estimated in the air averaged over the summer months in which ozone is highest (May–September) (EPA EJSCREEN, 2019).  This data is processed and obtained from the EPA’s [EJSCREEN](https://www.epa.gov/ejscreen).   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Particulate Matter 2.5 (PM 2.5)\n",
    "\n",
    "The PM 2.5 indicator represents a mix of particles smaller than 2.5 micrometers in the air produced by cars, trucks, and industries. PM2.5 is harmful to humans because it can move deep into our lungs and cause irritation, heart and lung disease, or cancer.\n",
    "\n",
    "The PM 2.5 indicator measures average annual concentrations of particulate matter that is 2.5 microns or less in diameter measured in the air in micrograms per cubic meter (µg/m3).  This data is estimated by the EPA using a combination of monitoring data and CMAQ air quality modeling from 2016. (EPA EJSCREEN, 2019)  This data is processed and obtained from the EPA’s [EJSCREEN](https://www.epa.gov/ejscreen). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the EJScreen dataframe accessing only the columns we need if you haven't already\n",
    "# ejscreen = pd.read_csv('data/EJSCREEN_2019_USPR.csv', usecols = [1,2,35,36], dtype = {'ID': str})\n",
    "# ejscreen['FIPS_tract_id'] = ejscreen['ID'].str[:-1]\n",
    "# ejscreen['State_ID'] = ejscreen['ID'].str[0:2]\n",
    "\n",
    "# ID column : Census block group fips code (12 digits, 12th digit as block group unique id)\n",
    "# The ID column is missing the initial 0 in front of single digit state codes so fill that initial 0 \n",
    "# Turn block level FIPS to tract level FIPS \n",
    "ejscreen['FIPS_block_group_id'] = list(map(lambda x: str.zfill(x, 12), ejscreen['ID'])) \n",
    "\n",
    "# Group by tract level FIPS to get distinct values and take only the first tract value\n",
    "ejscreen = ejscreen.groupby(\n",
    "    'FIPS_tract_id', \n",
    "    as_index = False).first().drop(['FIPS_block_group_id'], axis = 1)\n",
    "\n",
    "# Convert 'None' values to null values\n",
    "ejscreen = ejscreen.replace('None', np.nan)\n",
    "\n",
    "# Create ozone and PM 2.5 specific table\n",
    "ozone = ejscreen[['FIPS_tract_id', 'State_ID', 'OZONE']]\n",
    "pm25 = ejscreen[['FIPS_tract_id', 'State_ID', 'PM25']]\n",
    "\n",
    "# Rename 'OZONE' column to 'ozone_score' and PM25' column to 'PM25_score'\n",
    "ozone = ozone.rename(columns = {\n",
    "    'OZONE' : 'ozn_score',\n",
    "    'State_ID' : 'state'\n",
    "})\n",
    "pm25 = pm25.rename(columns = {\n",
    "    'PM25' : 'pm25_score',\n",
    "    'State_ID' : 'state'\n",
    "})\n",
    "\n",
    "# Convert \"ozone_score\" and \"pm25_score\" to floats\n",
    "ozone['ozn_score'] = ozone['ozn_score'].astype(float)\n",
    "pm25['pm25_score'] = pm25['pm25_score'].astype(float)\n",
    "\n",
    "# Calculate percentile rank for census tracts with a score above 0, set percentile to 0 if score is 0\n",
    "# For each indicator in each state\n",
    "ozone['ozn_rank'] = ozone[ozone['ozn_score'] != 0][['ozn_score','state']].groupby('state').rank(\n",
    "    na_option = 'keep', \n",
    "    pct = True) * 100\n",
    "ozone.loc[ozone['ozn_score'] == 0, 'ozn_rank'] = 0\n",
    "pm25['pm25_rank'] = pm25[pm25['pm25_score'] != 0][['pm25_score','state']].groupby('state').rank(\n",
    "    na_option = 'keep', \n",
    "    pct = True) * 100\n",
    "pm25.loc[pm25['pm25_score'] == 0, 'pm25_rank'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isolate the data for New Mexico\n",
    "NM_ozone = ozone[ozone['state'] == '35']\n",
    "NM_pm25 = pm25[pm25['state'] == '35']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Diesel Particulate Matter (Diesel PM) <a id='diesel'></a>\n",
    "\n",
    "The Diesel PM indicator represents small particles made by burning diesel. Diesel Particulate Matter is known to cause eye and throat irritation, along with heart and lung disease and lung cancer. \n",
    "\n",
    "The Diesel PM indicator measures concentrations of diesel particulate matter that is 10 microns or less in diameter measured in the air in micrograms per cubic meter (µg/m3). This data is obtained from the EPA’s [2014 National Air Toxics Assessment (NATA)](https://www.epa.gov/national-air-toxics-assessment/2014-nata-assessment-results), which models ambient air concentrations of air toxics using the National Emissions Inventory (NEI), a detailed, nationwide inventory of air toxics emissions including emissions from point, nonpoint and mobile sources, as well as emissions from biogenic sources and fires (EPA NATA, 2014). \n",
    "\n",
    "Note that this code creates a score and rank by state, for every state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data from MEJ github repo\n",
    "diesel = pd.read_csv(\"data/dieselpmexposure.csv\", dtype = {'Tract': object})\n",
    "\n",
    "# Remove rows for entire US or state\n",
    "diesel.drop(diesel[diesel['County'] == 'Entire State'].index, inplace = True)\n",
    "diesel.drop(diesel[diesel['County'] == 'Entire US'].index, inplace = True)\n",
    "\n",
    "# Rename columns\n",
    "diesel = diesel.rename(columns = {\"Total Exposure Conc\": \"dsl_score\",\n",
    "                                  \"Tract\" : \"FIPS_tract_id\",\n",
    "                                  'State' : 'state',\n",
    "                                  'County' : 'county'\n",
    "                                 })\n",
    "\n",
    "# Calculate percentile rank for census tracts with a score above 0, set percentile to 0 if score is 0, for each state\n",
    "diesel['dsl_rank'] = diesel[diesel['dsl_score'] != 0][['dsl_score','state']].groupby('state').rank( \n",
    "    na_option = 'keep', \n",
    "    pct = True) * 100\n",
    "diesel.loc[diesel['dsl_score'] == 0, 'dsl_rank'] = 0\n",
    "\n",
    "# Create final diesel table\n",
    "diesel = diesel[['state', 'county', 'FIPS_tract_id','dsl_score', 'dsl_rank']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isolate the data for New Mexico\n",
    "NM_diesel = diesel[diesel['state'] == 'NM']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Air Toxics <a id='air_toxics'></a>\n",
    "\n",
    "The Air Toxics indicator represents hazardous air pollutants from many sources including cars, trucks, and industrial facilities, and may cause cancer or other serious health effects. These include reproductive problems and birth defects.\n",
    "\n",
    "The Air Toxics indicator uses an index that represents the cumulative impacts of all the relevant air toxics for which respiratory effects were the key health effect. This data is obtained from the EPA’s [2014 National Air Toxics Assessment (NATA)](https://www.epa.gov/national-air-toxics-assessment/2014-nata-assessment-results), which calculates a hazard quotient that is the ratio of ambient air concentration to a chemical’s health-based RfC, a value used to determine the potential of a toxic effect (EPA NATA, 2014). A hazard index is the sum of hazard quotients for chemicals that cause adverse effects through the same toxic mechanism (EPA NATA, 2014). NATA’s respiratory effects hazard index represents the cumulative impacts of all the relevant air toxics for which respiratory effects were the key health effect.\n",
    "\n",
    "Data can be found on NATA's website, under the name [\"2014 NATA natl respiratory hazard index by pollutant (XLS)\"](https://www.epa.gov/sites/production/files/2018-08/nata2014v2_national_resphi_by_tract_poll.xlsx). \n",
    "\n",
    "Note that this code creates a score and rank by state, for every state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data from https://www.epa.gov/sites/production/files/2018-08/nata2014v2_national_resphi_by_tract_poll.xlsx\n",
    "toxics = pd.read_excel(\"data/nata2014v2_national_resphi_by_tract_poll.xlsx\", dtype = {'Tract': object})\n",
    "\n",
    "# Adding a State identifier to the toxics table for grouping\n",
    "toxics['state'] = toxics.Tract.astype(str).str[:2].astype(int)\n",
    "\n",
    "# Rename columns\n",
    "toxics = toxics.rename(columns = {\n",
    "    \"Total Respiratory (hazard quotient)\": \"txcs_score\",\n",
    "    \"Tract\" : \"FIPS_tract_id\",\n",
    "})\n",
    "\n",
    "# Calculate percentile rank for census tracts with a score above 0, set percentile to 0 if score is 0, for each state\n",
    "toxics['txcs_rank'] = toxics[toxics['txcs_score'] != 0][['txcs_score','state']].groupby('state').rank( \n",
    "    na_option = 'keep', \n",
    "    pct = True) * 100\n",
    "toxics.loc[toxics['txcs_score'] == 0, 'txcs_rank'] = 0\n",
    "\n",
    "# Create final table\n",
    "toxics = toxics[['state', 'FIPS_tract_id', 'txcs_score', 'txcs_rank']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NM_toxics = toxics[toxics['state'] == 35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Socioeconomic Factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Extreme Housing Burden <a id='housingburden'></a>\n",
    "\n",
    "The Extreme Housing Burden indicator represents the proportion of low-income households that have to spend more than half their income on rent. These households experience higher levels of stress, report lower health, and may delay medical treatment because of its high cost.\n",
    "\n",
    "The Extreme Housing Burden indicator measures the percent of households in a census tract that are:\n",
    "\n",
    "1. Making less than 80% of the Area Median Family Income as determined by the Department of Housing and Urban Development (HUD), and\n",
    "2. Paying greater than 50% of their income to housing costs. \n",
    "\n",
    "This data is sourced from the 2012-2016 Comprehensive Housing Affordability Strategy dataset from the Department of Housing and Urban Development (HUD) using the census tract geographic summary level, and contains cost burdens for households by percent HUD-adjusted median family income (HAMFI) category. This data can be found [here](https://www.huduser.gov/portal/datasets/cp.html). \n",
    "\n",
    "Because CHAS data is based on American Communities Survey (ACS) estimates, which come from a sample of the population, they may be unreliable if based on a small sample or population size. The standard error and relative standard error were used to evaluate the reliability of each estimate using CalEnviroScreen’s methodology. Census tract estimates that met either of the following criteria were considered reliable and included in the analysis(CalEnviroScreen, 2017): \n",
    "- Relative standard error less than 50 (meaning the standard error was less than half of the estimate), OR \n",
    "- Standard error less than the mean standard error of all census tract estimates \n",
    "\n",
    "Formulas for calculating the standard error of sums, proportions, and ratio come from the [American Communities Survey Office](https://www2.census.gov/programs-surveys/acs/tech_docs/accuracy/MultiyearACSAccuracyofData2013.pdf).\n",
    "\n",
    "Note that this code creates a score and rank by state, for every state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relevant variables in table 8 of the CHAS dataset are the following (CHAS data dictionary available [here](https://www.huduser.gov/portal/datasets/cp/CHAS-data-dictionary-12-16.xlsx)):\n",
    "\n",
    "|   Name  |                          Label                      |\n",
    "|---------|-----------------------------------------------------|\n",
    "|T1_est1  |                                   Total Occupied housing units                                      | \n",
    "|T8_est10 |            Owner occupied less than or equal to 30% of HAMFI cost burden greater than 50%           |\n",
    "|T8_est23 |Owner occupied greater than 30% but less than or equal to 50% of HAMFI\tcost burden greater than 50%|\n",
    "|T8_est36 |Owner occupied\tgreater than 50% but less than or equal to 80% of HAMFI\tcost burden greater than 50%|\n",
    "|T8_est76 |           Renter occupied less than or equal to 30% of HAMFI cost burden greater than 50%           |\n",
    "|T8_est89 |Renter occupied\tgreater than 30% but less than or equal to 50% of HAMFI\tcost burden greater than 50%|\n",
    "|T8_est102|Renter occupied\tgreater than 50% but less than or equal to 80% of HAMFI\tcost burden greater than 50%|\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data from https://www.huduser.gov/portal/datasets/cp.html\n",
    "\n",
    "housing = pd.read_csv(\"data/2012thru2016-140-csv/2012thru2016-140-csv/140/Table8.csv\",\n",
    "                      encoding = \"ISO-8859-1\", \n",
    "                      dtype = {'Tract_ID': object, 'st': object, 'geoid': object})\n",
    "\n",
    "# Save only the necessary variables\n",
    "housing = housing[['geoid', 'name', 'st', \n",
    "             'T8_est10', 'T8_moe10',\n",
    "             'T8_est23', 'T8_moe23', \n",
    "             'T8_est36','T8_moe36', \n",
    "             'T8_est76', 'T8_moe76',\n",
    "             'T8_est89', 'T8_moe89',\n",
    "             'T8_est102', 'T8_moe102', \n",
    "             'T8_est1', 'T8_moe1']]\n",
    "\n",
    "# Remove data for states that aren't included in the census (e.g. American Samoa, Guam, etc.):\n",
    "#housing.drop(housing.loc[housing['st'] == '72'].index, inplace = True)\n",
    "\n",
    "# Combine owner and renter occupied low-income households that make less than 80% of HAMFI into one variable\n",
    "housing['summed'] = (housing['T8_est10'] + \n",
    "                     housing['T8_est23'] + \n",
    "                     housing['T8_est36'] + \n",
    "                     housing['T8_est76'] + \n",
    "                     housing['T8_est89'] + \n",
    "                     housing['T8_est102'])\n",
    "\n",
    "# Create a variable for the standard error of the summed variables\n",
    "housing['summed_se'] = np.sqrt((housing['T8_moe10']/1.645)**2 + \n",
    "                                (housing['T8_moe23']/1.645)**2 + \n",
    "                                (housing['T8_moe36']/1.645)**2 + \n",
    "                                (housing['T8_moe76']/1.645)**2 + \n",
    "                                (housing['T8_moe89']/1.645)**2 + \n",
    "                                (housing['T8_moe102']/1.645)**2)\n",
    "\n",
    "# Remove the first 7 digits in the FIPS Census Tract ID \n",
    "housing['geoid'] = housing['geoid'].str[-11:]\n",
    "\n",
    "# Find the estimate of the proportion of the population that is heavily rent burdened\n",
    "housing['hbrd_score'] = housing['summed']/housing['T8_est1']\n",
    "\n",
    "# Change rates where the population is 0 to nan\n",
    "housing['hbrd_score'].replace(np.inf, np.nan, inplace = True)\n",
    "\n",
    "# Create function for calculating the standard error, using the proportions standard error formula\n",
    "#  if the value under the radical is negative, use the ratio standard error formula\n",
    "def se_prop(x, y, se_x, moe_y): \n",
    "    se_y = moe_y/1.645\n",
    "    test = se_x**2 - (((x**2)/(y**2))*((se_y)**2))\n",
    "    se = np.where(test < 0,\n",
    "                   (1/y) * np.sqrt(se_x**2 + (((x**2)/(y**2))*(se_y**2))), \n",
    "                   (1/y) * np.sqrt(se_x**2 - (((x**2)/(y**2))*(se_y**2))))\n",
    "    return se\n",
    "\n",
    "housing['se'] = se_prop(housing['summed'], housing['T8_est1'], housing['summed_se'], housing['T8_moe1'])\n",
    "\n",
    "# Calculate the relative standard error\n",
    "housing['rse'] = housing['se']/housing['hbrd_score']*100\n",
    "\n",
    "# Change infinite rse's where the housing burden is 0 to np.nan\n",
    "housing['rse'].replace(np.inf, np.nan, inplace = True)\n",
    "\n",
    "# Calculate the mean standard error for each state\n",
    "housing['mean_state_se'] = np.zeros(len(housing))\n",
    "for state in housing['st'].unique():\n",
    "    mean_se = np.mean(housing[housing['st'] == state]['se'])\n",
    "    housing['mean_state_se'].loc[housing['st'] == state] = mean_se\n",
    "    \n",
    "# Find census tract estimates that meet both of the following criteria and are thus considered unreliable estimates: \n",
    "# RSE less than 50 AND\n",
    "# SE less than the mean state SE or housing burdened low income households\n",
    "# Convert these scores to nan\n",
    "housing.loc[(housing['rse'] >= 50) & (housing['rse'] >= housing['mean_state_se']), 'hbrd_score'] = np.nan\n",
    "\n",
    "# Rename columns\n",
    "housing = housing.rename(columns = {'geoid' :'FIPS_tract_id',\n",
    "                                    'st' : 'state'\n",
    "                                   })\n",
    "\n",
    "# Calculate percentile rank for census tracts with a score above 0, set percentile to 0 if score is 0, for each state\n",
    "housing['hbrd_rank'] = housing[housing['hbrd_score'] != 0][['hbrd_score','state']].groupby('state').rank( \n",
    "    na_option = 'keep', \n",
    "    pct = True) * 100\n",
    "housing.loc[housing['hbrd_score'] == 0, 'hbrd_rank'] = 0\n",
    "\n",
    "# Create final housing burden df\n",
    "housingburden = housing[['state', 'FIPS_tract_id','hbrd_score','hbrd_rank']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NM_housingburden = housingburden[housingburden['state'] == '35']\n",
    "NM_housingburden.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14-17. No High School Degree, Linguistic Isolation, Unemployment, People of Color <a id='census'></a>\n",
    "\n",
    "The data for these four indicators comes from the 2018 American Communities Survey 5-year survey Data Profiles; therefore the following code pulls data for all four indicators.\n",
    "\n",
    "Note that this code creates scores and ranks for the following indicators by state, for every state.\n",
    "\n",
    "ACS geography codes can be found [here](https://api.census.gov/data/2018/acs/acs5/profile/geography.html).\n",
    "\n",
    "ACS 2018 5-year data profiles [variables](https://api.census.gov/data/2018/acs/acs5/profile/variables.html):\n",
    "\n",
    "|    Name   |                          Label                      |       Concept      |\n",
    "|-----------|-----------------------------------------------------|--------------------|\n",
    "|DP05_0033E | Estimate - RACE - Total Population |ACS DEMOGRAPHIC AND HOUSING ESTIMATES|\n",
    "|DP05_0033M | Margin of Error - RACE - Total population |ACS DEMOGRAPHIC AND HOUSING ESTIMATES|\n",
    "|DP02_0066PE|Percent Estimate - EDUCATIONAL ATTAINMENT - Population 25 years and over - High school graduate or higher|ACS DEMOGRAPHIC AND HOUSING ESTIMATES|\n",
    "|DP02_0066PM|Percent Margin of Error - EDUCATIONAL ATTAINMENT - Population 25 years and over - High school graduate or higher|ACS DEMOGRAPHIC AND HOUSING ESTIMATES|\n",
    "|DP02_0113PE|Percent Estimate - LANGUAGE SPOKEN AT HOME - Population 5 years and over - Language other than English - Speak English less than \"very well\"|SELECTED SOCIAL CHARACTERISTICS IN THE UNITED STATES|\n",
    "|DP02_0113PM|Percent Margin of Error - LANGUAGE SPOKEN AT HOME - Population 5 years and over - Language other than English - Speak English less than \"very well\"|SELECTED SOCIAL CHARACTERISTICS IN THE UNITED STATES|\n",
    "|DP03_0009PE|Percent Estimate - EMPLOYMENT STATUS - Civilian labor force - Unemployment Rate|SELECTED ECONOMIC CHARACTERISTICS|\n",
    "|DP03_0009PM|Percent Margin of Error - EMPLOYMENT STATUS - Civilian labor force - Unemployment Rate|SELECTED ECONOMIC CHARACTERISTICS|\n",
    "|DP05_0077PE|Percent Estimate - HISPANIC OR LATINO AND RACE - Total population - Not Hispanic or Latino - White alone|ACS DEMOGRAPHIC AND HOUSING ESTIMATES|\n",
    "|DP05_0077PM|Percent Margin of Error - HISPANIC OR LATINO AND RACE - Total population - Not Hispanic or Latino - White alone|ACS DEMOGRAPHIC AND HOUSING ESTIMATES|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty dataframe that will contain census data for all states\n",
    "census = pd.DataFrame(columns = ['NAME',\n",
    "                                 'state',\n",
    "                                 'county',\n",
    "                                 'tract',\n",
    "                                 'DP05_0033E',\n",
    "                                 'DP05_0033M',\n",
    "                                 'DP02_0066PE',\n",
    "                                 'DP02_0066PM',\n",
    "                                 'DP02_0113PE',\n",
    "                                 'DP02_0113PM',\n",
    "                                 'DP03_0009PE',\n",
    "                                 'DP03_0009PM',\n",
    "                                 'DP05_0077PE',\n",
    "                                 'DP05_0077PM'])\n",
    "                                          \n",
    "\n",
    "# Create the census api request to retrieve data\n",
    "date = \"2018\"\n",
    "dataset = '/acs/acs5/profile'\n",
    "base_url = \"https://api.census.gov/data\"\n",
    "variables = \"NAME,DP05_0033E,DP05_0033M,DP02_0066PE,DP02_0066PM,DP02_0113PE,DP02_0113PM,DP03_0009PE,DP03_0009PM,DP05_0077PE,DP05_0077PM\"\n",
    "\n",
    "# Get all FIPS state codes in strings (01 - 56) \n",
    "# FIPS state codes can be found here: https://en.wikipedia.org/wiki/Federal_Information_Processing_Standard_state_code\n",
    "state_codes = list(np.arange(1, 56))\n",
    "states = list(map(str, np.arange(1, 56)))\n",
    "states = list(map(lambda x: str.zfill(x, 2), states))\n",
    "\n",
    "# remove reserved codes that aren't included in the census (e.g. American Samoa, Guam, etc.):\n",
    "states.remove('03')\n",
    "states.remove('07')\n",
    "states.remove('14')\n",
    "states.remove('43')\n",
    "states.remove('52')\n",
    "\n",
    "# Request data for each state and add to dataframe for all states \n",
    "for state in states:\n",
    "    query = base_url + \"/\" + date + dataset + \"?get=\" + variables + '&for=' + 'tract:*&in=state:' + state\n",
    "\n",
    "    state_df = pd.read_json(query, dtype = True)\n",
    "    state_df.columns = state_df.iloc[0]\n",
    "    state_df = state_df.drop(state_df.index[0])\n",
    "    \n",
    "    # Concat all data into one table\n",
    "    census = pd.concat([census, state_df[['NAME',\n",
    "                                          'state',\n",
    "                                          'county',\n",
    "                                          'tract',\n",
    "                                          'DP05_0033E',\n",
    "                                          'DP05_0033M',\n",
    "                                          'DP02_0066PE',\n",
    "                                          'DP02_0066PM',\n",
    "                                          'DP02_0113PE',\n",
    "                                          'DP02_0113PM',\n",
    "                                          'DP03_0009PE',\n",
    "                                          'DP03_0009PM',\n",
    "                                          'DP05_0077PE',\n",
    "                                          'DP05_0077PM']]], sort = 'True', ignore_index = True)\n",
    "    \n",
    "# Rename columns\n",
    "census = census.rename(columns = {\"DP05_0033E\" : \"total_pop\",\n",
    "                                  \"DP05_0033M\" : \"total_pop_moe\",\n",
    "                                  \"DP02_0066PE\" : \"hs_degree\", \n",
    "                                  \"DP02_0066PM\" : \"hs_degree_moe\",\n",
    "                                  \"DP02_0113PE\" : \"linguistic_isolation\",\n",
    "                                  \"DP02_0113PM\" : \"linguistic_isolation_moe\",\n",
    "                                  \"DP03_0009PE\" : \"unemployment\",\n",
    "                                  \"DP03_0009PM\" : \"unemployment_moe\",\n",
    "                                  \"DP05_0077PE\" : \"white\",\n",
    "                                  \"DP05_0077PM\": \"white_moe\"})\n",
    "    \n",
    "# Construct the FIPS Code\n",
    "census['FIPS_tract_id'] = census['state'] + census['county'] + census['tract']\n",
    "\n",
    "# Change data types\n",
    "census[['total_pop', \n",
    "        'total_pop_moe', \n",
    "        'hs_degree', \n",
    "        'hs_degree_moe', \n",
    "        'linguistic_isolation', \n",
    "        'linguistic_isolation_moe',\n",
    "        'unemployment',\n",
    "        'unemployment_moe',\n",
    "        'white',\n",
    "        'white_moe']] = census[['total_pop', \n",
    "                               'total_pop_moe',\n",
    "                               'hs_degree', \n",
    "                               'hs_degree_moe', \n",
    "                               'linguistic_isolation', \n",
    "                               'linguistic_isolation_moe',\n",
    "                               'unemployment',\n",
    "                               'unemployment_moe',\n",
    "                               'white',\n",
    "                               'white_moe']].astype(float)\n",
    "\n",
    "# Replace null value codes with np.nan\n",
    "census = census.replace(-222222222.0, np.nan)\n",
    "census = census.replace(-666666666.0, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. No High School Degree (No HS Degree) <a id='no_hs'></a>\n",
    "\n",
    "The No High School Degree indicator represents the proportion of the population that is over 25 years old without a high school degree. There are strong links between higher levels of education and resistance to environmental toxic exposure.\n",
    "\n",
    "The No High High School Degree indicator measures the percent of the population over age 25 with no high school degree. This data is obtained from the 2013-2018 American Community Survey (ACS) data, which is estimated based on a sample of the population; therefore estimates may be unreliable if based on a small sample or population size. The standard error and relative standard error were used to evaluate the reliability of each estimate using CalEnviroScreen’s methodology. The standard error was calculated for each census tract by dividing the margin of error (MOE) reported in the ACS by 1.645, a statistical value associated with a 90 percent confidence interval. The MOE is the difference between an estimate and the upper or lower bounds of its confidence interval. All ACS-published MOEs are based on a 90 percent confidence interval. Census tract estimates that met either of the following criteria were considered reliable and included in the analysis (CalEnviroScreen, 2017): \n",
    "- Relative standard error less than 50 (meaning the standard error was less than half of the estimate), OR \n",
    "- Standard error less than the mean standard error of all census tract estimates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a no high school degree table\n",
    "no_hs = census[['hs_degree', 'hs_degree_moe', 'state', 'county', 'tract', 'FIPS_tract_id', 'total_pop']]\n",
    "\n",
    "# Create a no high school degree variable from the high school degree variable\n",
    "# And calculate the standard error from the moe for the high school degree variable\n",
    "no_hs['nohs_score'] = 100 - no_hs['hs_degree']\n",
    "no_hs['se'] = no_hs['hs_degree_moe']/1.645\n",
    "\n",
    "# Calculate the relative standard error \n",
    "no_hs['rse'] = no_hs['se']/no_hs['nohs_score']*100\n",
    "\n",
    "# Change infinite rse's where the no hs score is 0 to np.nan\n",
    "no_hs['rse'].replace(np.inf, np.nan, inplace = True)\n",
    "\n",
    "# Calculate the mean standard error for each state\n",
    "no_hs['mean_state_se'] = np.zeros(len(no_hs))\n",
    "for state in no_hs['state'].unique():\n",
    "    mean_se = np.mean(no_hs.loc[no_hs['state'] == state,'se'])\n",
    "    no_hs['mean_state_se'].loc[no_hs['state'] == state] = mean_se\n",
    "    \n",
    "# Find census tract estimates that meet both of the following criteria and are thus considered unreliable estimates: \n",
    "# RSE less than 50 AND\n",
    "# SE less than the mean state SE \n",
    "# Convert these scores to nan\n",
    "no_hs.loc[(no_hs['rse'] >= 50) & (no_hs['se'] >= no_hs['mean_state_se']), 'nohs_score'] = np.nan\n",
    "\n",
    "# Calculate percentile rank for census tracts with a score above 0, set percentile to 0 if score is 0, for each state\n",
    "no_hs['nohs_rank'] = no_hs[no_hs['nohs_score'] != 0][['nohs_score','state']].groupby('state').rank( \n",
    "    na_option = 'keep', \n",
    "    pct = True) * 100\n",
    "no_hs.loc[no_hs['nohs_score'] == 0, 'nohs_rank'] = 0\n",
    "\n",
    "# Only keep necessary columns\n",
    "no_hs = no_hs[['state', 'FIPS_tract_id', 'nohs_score', 'nohs_rank', 'total_pop']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NM_no_hs = no_hs[no_hs['state'] == '35']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Linguistic Isolation <a id='ling_iso'></a>\n",
    "\n",
    "The Linguistic Isolation indicator represents the percentage of households reporting that no-one over the age of 5 speaks English “very well.” These households tend to receive lower-quality medical care, and are often left out of decision-making by their local government. \n",
    "\n",
    "The Linguistic Isolation indicator measures the percent limited English-speaking households, where no one over the age of 5 speaks English “very well”. This data is obtained from the 2013-2018 American Community Survey (ACS) data, which is estimated based on a sample of the population; therefore estimates may be unreliable if based on a small sample or population size. The standard error and relative standard error were used to evaluate the reliability of each estimate using CalEnviroScreen’s methodology. The standard error was calculated for each census tract by dividing the margin of error (MOE) reported in the ACS by 1.645, a statistical value associated with a 90 percent confidence interval. The MOE is the difference between an estimate and the upper or lower bounds of its confidence interval. All ACS-published MOEs are based on a 90 percent confidence interval. Census tract estimates that met either of the following criteria were considered reliable and included in the analysis (CalEnviroScreen, 2017): \n",
    "- Relative standard error less than 50 (meaning the standard error was less than half of the estimate), OR \n",
    "- Standard error less than the mean standard error of all census tract estimates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a linguistic isolation table\n",
    "ling_iso = census[['linguistic_isolation', 'linguistic_isolation_moe', 'state', 'county', 'tract', 'FIPS_tract_id']]\n",
    "\n",
    "# Rename columnns\n",
    "ling_iso = ling_iso.rename(columns = {'linguistic_isolation' : 'liso_score',\n",
    "                                      'linguistic_isolation_moe' : 'liso_moe'})\n",
    "\n",
    "# Calculate the standard error from the margin of error\n",
    "ling_iso['se'] = ling_iso['liso_moe']/1.645\n",
    "\n",
    "# Calculate the relative standard error \n",
    "ling_iso['rse'] = ling_iso['se']/ling_iso['liso_score']*100\n",
    "\n",
    "# Change infinite rse's where the linguistic isolation score is 0 to np.nan\n",
    "ling_iso['rse'].replace(np.inf, np.nan, inplace = True)\n",
    "\n",
    "# Calculate the mean standard error for each state\n",
    "ling_iso['mean_state_se'] = np.zeros(len(ling_iso))\n",
    "for state in ling_iso['state'].unique():\n",
    "    mean_se = np.mean(ling_iso.loc[ling_iso['state'] == state,'se'])\n",
    "    ling_iso['mean_state_se'].loc[ling_iso['state'] == state] = mean_se\n",
    "    \n",
    "# Find census tract estimates that meet both of the following criteria and are thus considered unreliable estimates: \n",
    "# RSE less than 50 AND\n",
    "# SE less than the mean state SE \n",
    "# Convert these scores to nan\n",
    "ling_iso.loc[\n",
    "    (ling_iso['rse'] >= 50) & (ling_iso['se'] >= ling_iso['mean_state_se']), 'liso_score'] = np.nan\n",
    "\n",
    "# Calculate percentile rank for census tracts with a score above 0, set percentile to 0 if score is 0, for each state\n",
    "ling_iso['liso_rank'] = ling_iso[ling_iso['liso_score'] != 0][['liso_score','state']].groupby('state').rank( \n",
    "    na_option = 'keep', \n",
    "    pct = True) * 100\n",
    "ling_iso.loc[ling_iso['liso_score'] == 0, 'liso_rank'] = 0\n",
    "\n",
    "# Only keep necessary columns\n",
    "ling_iso = ling_iso[['state', 'FIPS_tract_id', 'liso_score', 'liso_rank']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NM_ling_iso = ling_iso[ling_iso['state'] == '35']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Unemployment <a id='unemploy'></a>\n",
    "\n",
    "The Unemployment indicator represents the proportion of adults who are unemployed. Unemployed people face high levels of stress, which is closely linked to health outcomes.\n",
    "\n",
    "The Unemployment indicator measures the percent of the population over the age of 16 that is unemployed and eligible for the labor force. This excludes retirees, students, homemakers, institutionalized persons except prisoners, those not looking for work, and military personnel on active duty. This data is obtained from the 2013-2018 American Community Survey (ACS) data, which is estimated based on a sample of the population; therefore estimates may be unreliable if based on a small sample or population size. The standard error and relative standard error were used to evaluate the reliability of each estimate using CalEnviroScreen’s methodology. The standard error was calculated for each census tract by dividing the margin of error (MOE) reported in the ACS by 1.645, a statistical value associated with a 90 percent confidence interval. The MOE is the difference between an estimate and the upper or lower bounds of its confidence interval. All ACS-published MOEs are based on a 90 percent confidence interval. Census tract estimates that met either of the following criteria were considered reliable and included in the analysis (CalEnviroScreen, 2017): \n",
    "- Relative standard error less than 50 (meaning the standard error was less than half of the estimate), OR \n",
    "- Standard error less than the mean standard error of all census tract estimates \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create an unemployment table\n",
    "unemploy = census[['unemployment', 'unemployment_moe', 'state', 'county', 'tract', 'FIPS_tract_id']]\n",
    "\n",
    "# Rename columnns\n",
    "unemploy = unemploy.rename(columns = {'unemployment' : 'unem_score',\n",
    "                                      'unemployment_moe' : 'unem_moe'})\n",
    "\n",
    "# Calculate the standard error from the margin of error\n",
    "unemploy['se'] = unemploy['unem_moe']/1.645\n",
    "\n",
    "# Calculate the relative standard error \n",
    "unemploy['rse'] = unemploy['se']/unemploy['unem_score']*100\n",
    "\n",
    "# Change infinite rse's where the unemployment rate is 0 to np.nan\n",
    "unemploy['rse'].replace(np.inf, np.nan, inplace = True)\n",
    "\n",
    "# Calculate the mean standard error for each state\n",
    "unemploy['mean_state_se'] = np.zeros(len(unemploy))\n",
    "for state in unemploy['state'].unique():\n",
    "    mean_se = np.mean(unemploy.loc[unemploy['state'] == state,'se'])\n",
    "    unemploy['mean_state_se'].loc[unemploy['state'] == state] = mean_se\n",
    "    \n",
    "# Find census tract estimates that meet both of the following criteria and are thus considered unreliable estimates: \n",
    "# RSE less than 50 AND\n",
    "# SE less than the mean state SE \n",
    "# Convert these scores to nan\n",
    "unemploy.loc[(unemploy['rse'] >= 50) & (unemploy['se'] >= unemploy['mean_state_se']), 'unem_score'] = np.nan\n",
    "\n",
    "# Calculate percentile rank for census tracts with a score above 0, set percentile to 0 if score is 0, for each state\n",
    "unemploy['unem_rank'] = unemploy[unemploy['unem_score'] != 0][['unem_score','state']].groupby('state').rank( \n",
    "    na_option = 'keep', \n",
    "    pct = True) * 100\n",
    "unemploy.loc[unemploy['unem_score'] == 0, 'unem_rank'] = 0\n",
    "\n",
    "# Only keep necessary columns\n",
    "unemploy = unemploy[['state', 'FIPS_tract_id', 'unem_score', 'unem_rank']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NM_unemploy = unemploy[unemploy['state'] == '35']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. People of Color <a id='poc'></a>\n",
    "\n",
    "The People of Color indicator represents the proportion of adults who identify as anything aside from “white only” on the census. People of color are drastically more affected by and exposed to pollution, have higher levels of stress, and are often systematically excluded from healthy housing, quality healthcare, and access to wealth.\n",
    "\n",
    "The People of Color indicator measures the percent of the population that is Black, American Indian/Alaskan Native, Asian, Native Hawaiian-Other Pacific Islander and two or more races, found by summing all race/ethnicity categories except White/Non-Hispanic. This data is obtained from the 2013-2018 American Community Survey (ACS) data, which is estimated based on a sample of the population; therefore estimates may be unreliable if based on a small sample or population size. The standard error and relative standard error were used to evaluate the reliability of each estimate using CalEnviroScreen’s methodology. The standard error was calculated for each census tract by dividing the margin of error (MOE) reported in the ACS by 1.645, a statistical value associated with a 90 percent confidence interval. The MOE is the difference between an estimate and the upper or lower bounds of its confidence interval. All ACS-published MOEs are based on a 90 percent confidence interval. Census tract estimates that met either of the following criteria were considered reliable and included in the analysis (CalEnviroScreen, 2017): \n",
    "- Relative standard error less than 50 (meaning the standard error was less than half of the estimate), OR \n",
    "- Standard error less than the mean standard error of all census tract estimates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a people of color table\n",
    "poc = census[['white', 'white_moe', 'state', 'county', 'tract', 'FIPS_tract_id']]\n",
    "\n",
    "# Calculate people of color population from white variable\n",
    "poc['poc_score'] = 100 - poc['white']\n",
    "\n",
    "# Rename columnns\n",
    "poc = poc.rename(columns = {'state' : 'state'})\n",
    "\n",
    "# Calculate the standard error from the margin of error\n",
    "poc['se'] = poc['white_moe']/1.645\n",
    "\n",
    "# Calculate the relative standard error \n",
    "poc['rse'] = poc['se']/poc['poc_score']*100\n",
    "\n",
    "# Change infinite rse's where the poc score is 0 to np.nan\n",
    "poc['rse'].replace(np.inf, np.nan, inplace = True)\n",
    "\n",
    "# Calculate the mean standard error for each state\n",
    "poc['mean_state_se'] = np.zeros(len(poc))\n",
    "for state in poc['state'].unique():\n",
    "    mean_se = np.mean(poc.loc[poc['state'] == state,'se'])\n",
    "    poc['mean_state_se'].loc[poc['state'] == state] = mean_se\n",
    "    \n",
    "# Find census tract estimates that meet both of the following criteria and are thus considered unreliable estimates: \n",
    "# RSE less than 50 AND\n",
    "# SE less than the mean state SE \n",
    "# Convert these scores to nan\n",
    "poc.loc[(poc['rse'] >= 50) & (poc['se'] >= poc['mean_state_se']), 'poc_score'] = np.nan\n",
    "\n",
    "# Calculate percentile rank for census tracts with a score above 0, set percentile to 0 if score is 0, for each state\n",
    "poc['poc_rank'] = poc[poc['poc_score'] != 0][['poc_score','state']].groupby('state').rank( \n",
    "    na_option = 'keep', \n",
    "    pct = True) * 100\n",
    "poc.loc[poc['poc_score'] == 0, 'poc_rank'] = 0\n",
    "\n",
    "# Only keep necessary columns\n",
    "poc = poc[['state', 'FIPS_tract_id', 'poc_score', 'poc_rank']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NM_poc = poc[poc['state'] == '35']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Poverty <a id='poverty'></a>\n",
    "\n",
    "The Poverty indicator represents the proportion of households with an income below double the Federal poverty line: $52,400 for a family of four. These households have higher stress, less access to healthcare, and are often much more affected by pollution.\n",
    "\n",
    "The Poverty indicator measures the percent of the population living below 200 percent of the federal poverty level, or $52,400 for a family of four. The number of individuals below the poverty level was divided by the total population for whom poverty status was determined to obtain a percent. This data is obtained from the 2013-2018 American Community Survey (ACS) Subject Tables, which is estimated based on a sample of the population; therefore estimates may be unreliable if based on a small sample or population size. The standard error and relative standard error were used to evaluate the reliability of each estimate using CalEnviroScreen’s methodology. The standard error was calculated for each census tract by dividing the margin of error (MOE) reported in the ACS by 1.645, a statistical value associated with a 90 percent confidence interval. The MOE is the difference between an estimate and the upper or lower bounds of its confidence interval. All ACS-published MOEs are based on a 90 percent confidence interval. Census tract estimates that met either of the following criteria were considered reliable and included in the analysis (CalEnviroScreen, 2017): \n",
    "- Relative standard error less than 50 (meaning the standard error was less than half of the estimate), OR \n",
    "- Standard error less than the mean standard error of all census tract estimates \n",
    "\n",
    "Note that this code creates a score and rank by state, for every state.\n",
    "\n",
    "ACS 2018 5-year subject tables [variables](https://api.census.gov/data/2018/acs/acs5/subject/variables.html):\n",
    "\n",
    "\n",
    "|    Name   |                          Label                      |       Concept      |\n",
    "|-----------|-----------------------------------------------------|--------------------|\n",
    "|S1701_C01_001E|Estimate - Total - Population for whom poverty status is determined|POVERTY STATUS IN THE PAST 12 MONTHS|\n",
    "|S1701_C01_001M|Margin of Error - Total - Population for whom poverty status is determined|POVERTY STATUS IN THE PAST 12 MONTHS|\n",
    "|S1701_C01_042E|Estimate - Total Population for whom poverty status is determined - ALL INDIVIDUALS WITH INCOME BELOW THE FOLLOWING POVERTY RATIOS - 200 percent of poverty level|POVERTY STATUS IN THE PAST 12 MONTHS|\n",
    "|S1701_C01_042M|Margin of Error - Total Population for whom poverty status is determined - ALL INDIVIDUALS WITH INCOME BELOW THE FOLLOWING POVERTY RATIOS - 200 percent of poverty level|POVERTY STATUS IN THE PAST 12 MONTHS|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create an empty dataframe that will contain poverty data for all states\n",
    "poverty = pd.DataFrame(columns = ['NAME',\n",
    "                                  'state',\n",
    "                                  'county',\n",
    "                                  'tract',\n",
    "                                  'S1701_C01_001E',\n",
    "                                  'S1701_C01_001M',\n",
    "                                  'S1701_C01_042E',\n",
    "                                  'S1701_C01_042M'])\n",
    "                                          \n",
    "\n",
    "# Create the census api request to retrieve data\n",
    "date = \"2018\"\n",
    "dataset = '/acs/acs5/subject'\n",
    "base_url = \"https://api.census.gov/data\"\n",
    "variables = \"NAME,S1701_C01_001E,S1701_C01_001M,S1701_C01_042E,S1701_C01_042M\"\n",
    "\n",
    "# Get all FIPS state codes in strings (01 - 56) \n",
    "# FIPS state codes can be found here: https://en.wikipedia.org/wiki/Federal_Information_Processing_Standard_state_code\n",
    "state_codes = list(np.arange(1, 56))\n",
    "states = list(map(str, np.arange(1, 56)))\n",
    "states = list(map(lambda x: str.zfill(x, 2), states))\n",
    "\n",
    "# remove reserved codes that aren't included in the census (e.g. American Samoa, Guam, etc.):\n",
    "states.remove('03')\n",
    "states.remove('07')\n",
    "states.remove('14')\n",
    "states.remove('43')\n",
    "states.remove('52')\n",
    "\n",
    "# Request data for each state and add to dataframe for all states \n",
    "for state in states:\n",
    "    query = base_url + \"/\" + date + dataset + \"?get=\" + variables + '&for=' + 'tract:*&in=state:' + state\n",
    "\n",
    "    state_df = pd.read_json(query, dtype = True)\n",
    "    state_df.columns = state_df.iloc[0]\n",
    "    state_df = state_df.drop(state_df.index[0])\n",
    "    \n",
    "    # Concat all data into one table\n",
    "    poverty = pd.concat([poverty, state_df[['NAME',\n",
    "                                            'state',\n",
    "                                            'county',\n",
    "                                            'tract',\n",
    "                                            'S1701_C01_001E',\n",
    "                                            'S1701_C01_001M',\n",
    "                                            'S1701_C01_042E',\n",
    "                                            'S1701_C01_042M']]], sort = 'True', ignore_index = True)\n",
    "    \n",
    "# Rename columns\n",
    "poverty = poverty.rename(columns = {'S1701_C01_001E' : 'total_pop',\n",
    "                                    'S1701_C01_001M' : 'total_pop_moe',\n",
    "                                    'S1701_C01_042E': 'below200pl',\n",
    "                                    'S1701_C01_042M': 'below200pl_moe',\n",
    "                                   })\n",
    "    \n",
    "# Construct the FIPS Code\n",
    "poverty['FIPS_tract_id'] = poverty['state'] + poverty['county'] + poverty['tract']\n",
    "\n",
    "# Clean datatypes\n",
    "poverty = poverty.fillna(value = np.nan)\n",
    "poverty = poverty.astype(dtype = {\n",
    "    'total_pop' : float,\n",
    "    'total_pop_moe' : float,\n",
    "    'below200pl' : float,\n",
    "    'below200pl_moe' : float\n",
    "})\n",
    "\n",
    "# Create the poverty rate variable\n",
    "poverty['poverty_rate'] = (poverty['below200pl']/poverty['total_pop'])*100\n",
    "\n",
    "# Create function for calculating the standard error, using the proportions standard error formula\n",
    "#  if the value under the radical is negative, use the ratio standard error formula\n",
    "def se_prop(x, y, moe_x, moe_y): \n",
    "    se_x = moe_x/1.645\n",
    "    se_y = moe_y/1.645\n",
    "    test = se_x**2 - (((x**2)/(y**2))*((se_y)**2))\n",
    "    se = np.where(test < 0,\n",
    "                   (1/y) * np.sqrt(se_x**2 + (((x**2)/(y**2))*(se_y**2))), \n",
    "                   (1/y) * np.sqrt(se_x**2 - (((x**2)/(y**2))*(se_y**2))))\n",
    "    return se\n",
    "\n",
    "# Calculate the poverty rate standard error using the standard error function for proportions\n",
    "poverty['se'] = se_prop(poverty['below200pl'], poverty['total_pop'], poverty['below200pl_moe'], poverty['total_pop_moe'])\n",
    "\n",
    "# Calculate the relative standard error\n",
    "poverty['rse'] = poverty['se']/(poverty['poverty_rate']/100)*100\n",
    "\n",
    "# Change infinite rse's where the poverty rate is 0 to np.nan\n",
    "poverty.replace(np.inf, np.nan, inplace = True)\n",
    "\n",
    "# Rename columns\n",
    "poverty = poverty.rename(columns = {'poverty_rate' : 'pov_score'})\n",
    "\n",
    "# Calculate the mean standard error for each state\n",
    "poverty['mean_state_se'] = np.zeros(len(poverty))\n",
    "for state in poverty['state'].unique():\n",
    "    mean_se = np.mean(poverty.loc[poverty['state'] == state, 'se'])\n",
    "    poverty['mean_state_se'].loc[poverty['state'] == state] = mean_se\n",
    "    \n",
    "# Find census tract estimates that meet both of the following criteria and are thus considered unreliable estimates: \n",
    "# RSE less than 50 AND\n",
    "# SE less than the mean state SE \n",
    "# Convert these scores to nan\n",
    "poverty.loc[(poverty['rse'] >= 50) & (poverty['se'] >= poverty['mean_state_se']), 'pov_score'] = np.nan\n",
    "\n",
    "# Calculate percentile rank for census tracts with a score above 0, set percentile to 0 if score is 0, for each state\n",
    "poverty['pov_rank'] = poverty[poverty['pov_score'] != 0][['pov_score','state']].groupby('state').rank( \n",
    "    na_option = 'keep', \n",
    "    pct = True) * 100\n",
    "poverty.loc[poverty['pov_score'] == 0, 'pov_rank'] = 0\n",
    "\n",
    "# Only keep necessary columns\n",
    "poverty = poverty[['state', 'FIPS_tract_id', 'pov_score', 'pov_rank']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NM_poverty = poverty[poverty['state'] == '35']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitive Populations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. Asthma <a id='asthma'></a>\n",
    " \n",
    "The Asthma indicator represents the proportion of the population with chronic lung disease that causes breathlessness, wheezing, coughing, and chest tightness, which may be caused or made worse by exposure to traffic and outdoor air pollutants. It also makes people much more vulnerable to some forms of pollution.\n",
    "\n",
    "The Asthma indicator measures the predicted prevalence of Asthma among adults. Asthma is defined as ever being diagnosed with Asthma by a doctor, nurse, or other health professional, and still having the condition. The estimate for each census tract represents an average that was derived from data covering 2014-2017, using a model-based approach developed by the Colorado Department of Public Health and Environment (CDPHE). CDPHE modelled Asthma prevalence by measuring the relationship between age, race, gender, poverty, education, location and health conditions or risk behavior indicators and applying this relationship to predict the number of persons' who have Asthma in each census tract (CDPHE, 2019). This data was obtained directly from [CDPHE](https://data-cdphe.opendata.arcgis.com/datasets/asthma-prevalence-in-adults-cdphe-community-level-estimates-census-tracts).\n",
    "\n",
    "Note that this indicator is only calculated for the state of Colorado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the CDPHE asthma data from https://data-cdphe.opendata.arcgis.com/datasets/asthma-prevalence-in-adults-cdphe-community-level-estimates-census-tracts\n",
    "asthma = pd.read_csv(\"data/DXAsthmaEverAA04_10.csv\", dtype = {'Census_Tract_FIPS': object})\n",
    "\n",
    "# Change column names and keep only the columns we need\n",
    "asthma = asthma.rename(columns = {'Census_Tract_FIPS' : 'FIPS_tract_id',\n",
    "                         'Asthma_Census_Tract_Estimate' : 'asth_score'\n",
    "                         })\n",
    "asthma = asthma[['FIPS_tract_id', 'asth_score']]\n",
    "\n",
    "# Add in Colorado state identifier\n",
    "asthma['state'] = '08'\n",
    "\n",
    "# Calculate percentile rank for census tracts with a score above 0, set percentile to 0 if score is 0\n",
    "asthma['asth_rank'] = asthma[asthma['asth_score'] != 0]['asth_score'].rank( \n",
    "    na_option = 'keep', \n",
    "    pct = True) * 100\n",
    "asthma.loc[asthma['asth_score'] == 0, 'asth_rank'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the CDPHE asthma data from https://data-cdphe.opendata.arcgis.com/datasets/asthma-prevalence-in-adults-cdphe-community-level-estimates-census-tracts\n",
    "asthma = pd.read_csv(\"data/DXAsthmaEverAA04_10.csv\", header = 8, skiprows = [9,10], nrows = 35, sep = ';')\n",
    "                    #, dtype = {'Census_Tract_FIPS': object})\n",
    "\n",
    "# Change column names and keep only the columns we need\n",
    "#asthma = asthma.rename(columns = {'CountyID' : 'FIPS_tract_id',\n",
    "                         #'Asthma_Census_Tract_Estimate' : 'percentage'})\n",
    "    \n",
    "asthma = asthma[['County', 'Percentage']]\n",
    "\n",
    "# Add in Colorado state identifier\n",
    "asthma['state'] = '35'\n",
    "\n",
    "# Calculate percentile rank for census tracts with a score above 0, set percentile to 0 if score is 0\n",
    "asthma['asth_rank'] = asthma[asthma['Percentage'] != 0]['Percentage'].rank( \n",
    "    na_option = 'keep', \n",
    "    pct = True) * 100\n",
    "asthma.loc[asthma['Percentage'] == 0, 'asth_rank'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asthma.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. Heart Disease <a id='heart_disease'></a>\n",
    "\n",
    "The Heart Disease indicator represents the proportion of the population with heart disease, specifically coronary heart disease, which can partially or completely block blood flow in the large arteries of the heart, causing chest pain or a heart attack. There is strong evidence that air pollution contributes to coronary heart disease and death following a heart attack.\n",
    "\n",
    "The Heart Disease indicator measures the predicted prevalence of Coronary Heart Disease among adults. The estimate for each census tract represents an average that was derived from data covering 2014-2017, using a model-based approach developed by the Colorado Department of Public Health and Environment (CDPHE). CDPHE modelled Coronary Heart Disease by measuring the relationship between age, race, gender, poverty, education, location and health conditions or risk behavior indicators and applying this relationship to predict the number of persons' who have Coronary Heart Disease in each census tract (CDPHE, 2019). This data was obtained directly from [CDPHE](https://data-cdphe.opendata.arcgis.com/datasets/heart-disease-in-adults-cdphe-community-level-estimates-census-tracts).\n",
    "\n",
    "Note that this indicator is only calculated for Colorado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the CDPHE heart disease data from https://data-cdphe.opendata.arcgis.com/datasets/heart-disease-in-adults-cdphe-community-level-estimates-census-tracts\n",
    "heart = pd.read_csv(\"data/Heart_Disease_in_Adults_-_CDPHE_Community_Level_Estimates__Census_Tracts_.csv\", \n",
    "                     dtype = {'Census_Tract_FIPS': object})\n",
    "\n",
    "# Change column names and keep only the columns we need\n",
    "heart = heart.rename(columns = {'Census_Tract_FIPS' : 'FIPS_tract_id',\n",
    "                                'HeartDisease_Census_Tract_Estimate' : 'hd_score'\n",
    "                               })\n",
    "heart = heart[['FIPS_tract_id', 'hd_score']]\n",
    "\n",
    "# Add in New Mexico state identifier\n",
    "heart['state'] = '35'\n",
    "\n",
    "# Calculate percentile rank for census tracts with a score above 0, set percentile to 0 if score is 0\n",
    "heart['hd_rank'] = heart[heart['hd_score'] != 0]['hd_score'].rank( \n",
    "    na_option = 'keep', \n",
    "    pct = True) * 100\n",
    "heart.loc[heart['hd_score'] == 0, 'hd_rank'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NM_heart = heart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. Low Birthweight Infants <a id='lbw'></a>\n",
    "\n",
    "The Low Birthweight Infants indicator represents the proportion of low birthweight infant births, where infants are born early or underweight, weighing 5 pounds and 8 ounces or less. Low birthweight infants have a high risk of infant mortality, or of having chronic health conditions later in life that may increase sensitivity to pollution.\n",
    "\n",
    "The Low Birthweight Infants indicator measures the low birthweight rate where low weight births are defined as infants weighing 5 pounds, 8 ounces or less (under 2,500 grams) at birth. This data contains the Crude Colorado Census Tract Low Weight Birth Rate which equals the total number of low weight births (singleton low weight births) divided by the denominator of all singleton births (2013-2017).  This data is from the Colorado Department of Public Health and Environment's Vital Records Birth Dataset and was obtained directly from the [Colorado Department of Public Health and Environment (CDPHE)](https://data-cdphe.opendata.arcgis.com/datasets/low-weight-birth-rate-census-tracts). \n",
    "\n",
    "Note that this indicator is only calculated for Colorado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read in the CDPHE lbw data from https://data-cdphe.opendata.arcgis.com/datasets/low-weight-birth-rate-census-tracts\n",
    "# lbw = pd.read_csv(\"data/Low_Weight_Birth_Rate__Census_Tracts_.csv\", \n",
    "#                      dtype = {'TRACT_FIPS': object})\n",
    "\n",
    "# # Change column names and keep only the columns we need\n",
    "# lbw = lbw.rename(columns = {'TRACT_FIPS' : 'FIPS_tract_id',\n",
    "#                             'LWB_ADJRATE' : 'lbw_score'\n",
    "#                            })\n",
    "# lbw = lbw[['FIPS_tract_id', 'lbw_score']]\n",
    "\n",
    "# # Add in New Mexico state identifier\n",
    "# lbw['state'] = '35'\n",
    "\n",
    "# # Calculate percentile rank for census tracts with a score above 0, set percentile to 0 if score is 0\n",
    "# lbw['lbw_rank'] = lbw[lbw['lbw_score'] != 0]['lbw_score'].rank( \n",
    "#     na_option = 'keep', \n",
    "#     pct = True) * 100\n",
    "# lbw.loc[lbw['lbw_score'] == 0, 'lbw_rank'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the census track data and the low weight data from two seperate data sheets. \n",
    "# You could use url to read the census track csv if system allows.\n",
    "url_census_track = \"https://ibis.health.state.nm.us/view/docs/PopData/CSVfiles/popepitrct10_18_28jun2019.csv\"\n",
    "census_track_va = pd.read_csv(\"popepitrct10_18_28jun2019.csv\")\n",
    "low_weight_va = pd.read_excel(\"Birthweight_va.xlsx\", dtype = {'Tract': object})\n",
    "\n",
    "# Merge two datasets\n",
    "lbw = low_weight_va.merge(census_track_va, how = \"left\", left_on = \"NM Small Areas ID\", right_on = \"sarea134\")\n",
    "\n",
    "# Change the unit of percentage and keep only the columns we need \n",
    "lbw[\"Percentage of Infants Under 2500 Grams\"] = lbw[\"Percentage of Infants Under 2500 Grams\"]*100\n",
    "lbw[\"fipstrct10\"] = lbw[\"fipstrct10\"].astype(str)\n",
    "lbw = lbw[[\"fipstrct10\",\"Percentage of Infants Under 2500 Grams\"]].drop_duplicates().drop(0)\n",
    "\n",
    "# Correct the ID format, rename the columns\n",
    "ID = []\n",
    "fipstrict10 = lbw[\"fipstrct10\"]\n",
    "for item in fipstrict10:\n",
    "    ID.append(item[0:11])\n",
    "lbw[\"fipstrct10\"] = ID\n",
    "lbw = lbw.rename(columns = {'fipstrct10' : 'FIPS_tract_id',\n",
    "                            'Percentage of Infants Under 2500 Grams' : 'lbw_score'\n",
    "                           })\n",
    "# Add in New Mexico state identifier\n",
    "lbw['state'] = '35'\n",
    "\n",
    "# Calculate percentile rank for census tracts with a score above 0, set percentile to 0 if score is 0\n",
    "lbw['lbw_rank'] = lbw[lbw['lbw_score'] != 0]['lbw_score'].rank( \n",
    "    na_option = 'keep', \n",
    "    pct = True) * 100\n",
    "lbw.loc[lbw['lbw_score'] == 0, 'lbw_rank'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NM_lbw = lbw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still missing for New Mexico: Oil & Gas, Extreme Housing Burden, Sensitive populations (Asthma, Heart Disease, Low Birth Weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining all indicators into one table for New Mexico <a id='all'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge all indicator tables to create one comprehensive table and calculate subcomponent, component, and final scores for census tracts in Colorado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all indicator tables to create comprehensive table\n",
    "mej_nm = lead.merge(\n",
    "    #oil_gas, how = 'outer', on = 'FIPS_tract_id', validate = 'one_to_one', suffixes = (None, '_y')).merge(\n",
    "    chemicals, how = 'outer', on = 'FIPS_tract_id', validate = 'one_to_one', suffixes = (None, '_y')).merge(\n",
    "    haz_waste, how = 'outer', on = 'FIPS_tract_id', validate = 'one_to_one', suffixes = (None, '_y')).merge(\n",
    "    cleanups, how = 'outer', on = 'FIPS_tract_id', validate = 'one_to_one', suffixes = (None, '_y')).merge(\n",
    "    water, how = 'outer', on = 'FIPS_tract_id', validate = 'one_to_one', suffixes = (None, '_y')).merge(\n",
    "    traffic, how = 'outer', on = 'FIPS_tract_id', validate = 'one_to_one', suffixes = (None, '_y')).merge(\n",
    "    ozone, how = 'outer', on = 'FIPS_tract_id', validate = 'one_to_one', suffixes = (None, '_y')).merge(\n",
    "    pm25, how = 'outer', on = 'FIPS_tract_id', validate = 'one_to_one', suffixes = (None, '_y')).merge(\n",
    "    diesel, how = 'outer', on = 'FIPS_tract_id', validate = 'one_to_one', suffixes = (None, '_y')).merge(\n",
    "    toxics, how = 'outer', on = 'FIPS_tract_id', validate = 'one_to_one', suffixes = (None, '_y')).merge(\n",
    "    #housingburden, how = 'outer', on = 'FIPS_tract_id', validate = 'one_to_one', suffixes = (None, '_y')).merge(\n",
    "    no_hs, how = 'outer', on = 'FIPS_tract_id', validate = 'one_to_one', suffixes = (None, '_y')).merge(\n",
    "    ling_iso, how = 'outer', on = 'FIPS_tract_id', validate = 'one_to_one', suffixes = (None, '_y')).merge(\n",
    "    unemploy, how = 'outer', on = 'FIPS_tract_id', validate = 'one_to_one', suffixes = (None, '_y')).merge(    \n",
    "    poc, how = 'outer', on = 'FIPS_tract_id', validate = 'one_to_one', suffixes = (None, '_y')).merge(\n",
    "    poverty, how = 'outer', on = 'FIPS_tract_id', validate = 'one_to_one', suffixes = (None, '_y'))#.merge(\n",
    "    #asthma, how = 'outer', on = 'FIPS_tract_id', validate = 'one_to_one', suffixes = (None, '_y')).merge(\n",
    "    #heart, how = 'outer', on = 'FIPS_tract_id', validate = 'one_to_one', suffixes = (None, '_y')).merge(\n",
    "    #lbw, how = 'outer', on = 'FIPS_tract_id', validate = 'one_to_one', suffixes = (None, '_y'))\n",
    "mej_nm.drop(columns = ['state_y'], inplace = True)\n",
    "\n",
    "# Filter dataframe to only New Mexico census tracts\n",
    "mej_nm = mej_nm.loc[mej_nm['state'] == '35'].reset_index(drop = True)\n",
    "\n",
    "# Add in county name\n",
    "mej_nm['county'] = mej_nm['NAME'].apply(lambda x: x.split(\",\")[1])\n",
    "\n",
    "# Find the number of missing indicator scores for each census tract\n",
    "mej_nm['missing_values'] = mej_nm.isnull().sum(axis = 1)\n",
    "\n",
    "# Calculate subcomponent scores\n",
    "# Environmental Effects Indicators\n",
    "mej_nm['enef_score'] = mej_nm[[\n",
    "    'lead_rank',\n",
    "    #'oil_rank',\n",
    "    'chem_rank',\n",
    "    'hazw_rank',\n",
    "    'cln_rank',\n",
    "    'wat_rank']].mean(axis = 1)\n",
    "mej_nm['enef_rank'] = mej_nm[mej_nm['enef_score'] != 0]['enef_score'].rank( \n",
    "    na_option = 'keep', \n",
    "    pct = True) * 100\n",
    "mej_nm.loc[mej_nm['enef_score'] == 0, 'enef_rank'] = 0\n",
    "\n",
    "# Exposure Indicators\n",
    "mej_nm['expo_score'] = mej_nm[[\n",
    "    'traf_rank',\n",
    "    'ozn_rank',\n",
    "    'pm25_rank',\n",
    "    'dsl_rank',\n",
    "    'txcs_rank']].mean(axis = 1)\n",
    "mej_nm['expo_rank'] = mej_nm['expo_score'].rank(na_option = 'keep', pct = True)*100\n",
    "\n",
    "# Socioeconomic Factor Indicators\n",
    "mej_nm['sef_score'] = mej_nm[[\n",
    "    #'hbrd_rank',\n",
    "    'nohs_rank',\n",
    "    'liso_rank',\n",
    "    'unem_rank',\n",
    "    'poc_rank',  \n",
    "    'pov_rank']].mean(axis = 1)\n",
    "mej_nm['sef_rank'] = mej_nm[mej_nm['sef_score'] != 0]['sef_score'].rank( \n",
    "    na_option = 'keep', \n",
    "    pct = True) * 100\n",
    "mej_nm.loc[mej_nm['sef_score'] == 0, 'sef_rank'] = 0\n",
    "\n",
    "# Calculating Sensitive Population Score\n",
    "#mej_nm['spop_score'] = mej_nm[[\n",
    "    #'asth_rank',\n",
    "    #'hd_rank',\n",
    "    #'lbw_rank'\n",
    "    #]].mean(axis = 1)\n",
    "#mej_nm['spop_rank'] = mej_nm[mej_nm['spop_score'] != 0]['spop_score'].rank( \n",
    "    #na_option = 'keep', \n",
    "    #pct = True) * 100\n",
    "#mej_nm.loc[mej_nm['spop_score'] == 0, 'spop_rank'] = 0\n",
    "\n",
    "# Calculate component scores\n",
    "# Calculating Pollution Burden score and rank\n",
    "mej_nm['pltn_score'] = (mej_nm['expo_score'] + (.5 * mej_nm['enef_score']))/1.5\n",
    "mej_nm['pltn_rank'] = mej_nm['pltn_score'].rank(na_option = 'keep', pct = True)*100\n",
    "\n",
    "# Calculating Pop Characteristics score and rank, removing scores for census tracts with no population\n",
    "mej_nm['pop_score'] = (mej_nm['sef_score'] + mej_nm['spop_score'])/2\n",
    "mej_nm['pop_score'].loc[mej_nm['total_pop'] == 0] = np.nan\n",
    "mej_nm['pop_rank'] = mej_nm['pop_score'].rank(na_option = 'keep', pct = True)*100\n",
    "\n",
    "# Calculate overall cumulative ej impact score\n",
    "# Combine Pollution Burden and Population Characteristics, scaling both to 10\n",
    "mej_nm['fin_score'] = ((mej_nm['pltn_score']/mej_nm['pltn_score'].max()*10) *\n",
    "                         (mej_nm['pop_score']/mej_nm['pop_score'].max()*10))\n",
    "# Remove cumulative ej impact score for tracts with more than two missing indicator scores\n",
    "mej_nm['fin_score'].loc[mej_nm['missing_values'] > 4] = np.nan\n",
    "mej_nm['fin_rank'] = mej_nm['fin_score'].rank(na_option = 'keep', pct = True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export csv\n",
    "if not os.path.exists('./data/mej_colorado_final'):\n",
    "    os.mkdir('./data/mej_colorado_final')\n",
    "mej_co.to_csv('data/mej_colorado_final/mej_colorado_final.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export as shapefile\n",
    "\n",
    "Merge with census tract spatial data to export as shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read in census tract spatial data for New Mexico available here if you haven't already: https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html\n",
    "NM_cts = gpd.read_file('data/cb_2018_35_tract_500k/cb_2018_35_tract_500k.shp')\n",
    "\n",
    "# Merge the census tract dataframe with the mej colorado dataframe\n",
    "mej_NM_spatial = mej_NM.merge(\n",
    "    NM_cts, \n",
    "    how = 'outer', \n",
    "    left_on = 'FIPS_tract_id', \n",
    "    right_on = 'FIPS',\n",
    "    validate = 'one_to_one')\n",
    "mej_NM_spatial.drop(columns = ['OBJECTID', 'FIPS'], inplace = True)\n",
    "mej_NM_spatial = gpd.GeoDataFrame(mej_NM_spatial)\n",
    "\n",
    "# Export as shapefile\n",
    "mej_NM_spatial.to_file(\"data/mej_colorado_final/mej_colorado_final.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Database\n",
    "\n",
    "Create tables to input into database and upload to MYSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read in census tract spatial data for New Mexico available here if you haven't already: https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html\n",
    "#NM_cts = gpd.read_file('data/cb_2018_35_tract_500k/cb_2018_35_tract_500k.shp')\n",
    "\n",
    "# # Remove unneccesary columns from final indicator table\n",
    "#NM_db = mej_co.drop(columns = ['state', 'county', 'geometry'])\n",
    "\n",
    "# # Create census tract table\n",
    "#NM_cts = co_db[[\"NAME\", \"FIPS_tract_id\"]]\n",
    "#NM_cts.set_index(\"FIPS_tract_id\")\n",
    "\n",
    "# # Set up database connection\n",
    "#conn = sqlite3.connect(\"MEJ.db\")\n",
    "#engine = create_engine(\"mysql+pymysql://{user}:{pw}@localhost/{db}\".format(\n",
    "    #user = \"root\",\n",
    "    #pw = \"envjust2020\",\n",
    "    #db = \"NM\"))\n",
    "\n",
    "# # Create databases\n",
    "#NM_db.to_sql(\"CENSUS_TRACT\", con = engine, if_exists = \"append\", index = False)\n",
    "#NM_cts.to_sql(\"CENSUS_TRACT\", con = engine, if_exists = \"append\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
